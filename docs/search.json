[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "UMN EEB Quant/Comp Repo",
    "section": "",
    "text": "Hello!\nThis site/book will serve as a repository for resources related to computational and quantitative workshops held for the University of Minnesota’s Ecology, Evolution, and Behavior Graduate Program through its “Friday Noon Seminar” series.\nIt is a “living document,” and thus will be subject to change and be updated over time.\nContact: Chris Wojan, wojan002 (at umn.edu)",
    "crumbs": [
      "Hello!"
    ]
  },
  {
    "objectID": "intro_iteration.html",
    "href": "intro_iteration.html",
    "title": "1  Intro to Iteration",
    "section": "",
    "text": "This workshop will be focused on iteration, or performing the same code numerous times, potentially on some range of values, in R. It assumes that you know most of the basics of R programming.\nR has various ways to iterate, including looping, using functions/functionals, and vectorization. We will go over each to some extent, with examples included. A general guideline for iterating is that if you are copying and pasting code multiple times, you may be better served with a loop or a function. We will cover the following:\n\nLoops\n\nTypes of loops: for, while, and repeat\nWhen to use which types of loops\nPotential downsides of using loops\nWhen use a loop is still necessary anyway\n\nFunctions and Functionals\n\nHow to write functions\nBenefits of functions\nHow to iterate functions with the purr package\nHow to iterate even faster with parallel computing\n\nVectorization\n\nBenefits of vectorization\nLimitations",
    "crumbs": [
      "Iteration: Loops, Functions, and the purr package",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to Iteration</span>"
    ]
  },
  {
    "objectID": "loop_types.html",
    "href": "loop_types.html",
    "title": "2  Types of Loops",
    "section": "",
    "text": "The first method of iteration that most people learn is looping, or using flow control to rerun a block of code some number of times, or over a range of values. Many of you will be familiar with this, so we will just review it a bit.\nR has different type of loops, including for, while, and repeat.\n\n2.0.1 for loops\nfor loops are the most commonly used loop, as they are versatile to many contexts. They generally follow the form:\n\nfor (indexing_variable in range_of_values) {\n  some_function(some_argument = indexing_variable)\n}\n\nIn the first line, an indexing variable is created to keep track of iterations, and it iterates through the range of values provided.\nThen, some code is provided within brackets to be performed for each value in the range of values. Usually, the indexing variable will be referenced somehow in this code, but it doesn’t need to be if you are just doing the same exact thing several times.\nHere is a really silly working example:\n\n## square the numbers 1 through 5\nfor (i in 1:5) {\n  print(i^2)\n}\n\n[1] 1\n[1] 4\n[1] 9\n[1] 16\n[1] 25\n\n## of course you could just do this instead and get a more useable vector\n(1:5)^2\n\n[1]  1  4  9 16 25\n\n\nNow let’s look at a more interesting example. Let’s say you are interested in the effect of some independent variable on multiple dependent variables. First let’s simulate some fake data of greenhouse plant growth under two watering conditions:\n\n## create a data frame with 60 total plants and\n## -two treatment levels, control and drought\n## -plant heights, masses, and seed masses sampling from a normal distribution\nplant_data &lt;- data.frame(treatment = rep(c(\"control\",\"drought\"), each = 30),\n                         height_cm = rnorm(n = 60, mean = rep(c(12,8), each = 30), sd = 2),\n                         dry_biomass_g = rnorm(60, mean = rep(c(50, 40), each = 30), sd = 6),\n                         seed_mass_mg = rnorm(60, mean = rep(c(30, 20), each = 30), sd = 4))\n\nNow we are probably interested in how the watering influences these variables (i.e., with a t-test), but we don’t want to write the code, and then copy and paste it twice. Here’s how we use a for loop:\n\n## create a vector of dependent variables to loop over\ndep_vars &lt;- c(\"height_cm\", \"dry_biomass_g\", \"seed_mass_mg\")\n\n## pre allocate a list to store results\nresult_list &lt;- vector(mode = \"list\", length = length(dep_vars))\n\n## let's name the list as well\nnames(result_list) &lt;- dep_vars\n\n## set up a loop to iterate through variables\nfor (i in dep_vars) {\n  ## store t test results in our list\n  result_list[[i]] &lt;- t.test(plant_data[,i] ~ plant_data[,\"treatment\"])\n}\n\n## check out the results!\nresult_list\n\n$height_cm\n\n    Welch Two Sample t-test\n\ndata:  plant_data[, i] by plant_data[, \"treatment\"]\nt = 7.8682, df = 57.708, p-value = 1.052e-10\nalternative hypothesis: true difference in means between group control and group drought is not equal to 0\n95 percent confidence interval:\n 2.852358 4.799160\nsample estimates:\nmean in group control mean in group drought \n            12.047247              8.221488 \n\n\n$dry_biomass_g\n\n    Welch Two Sample t-test\n\ndata:  plant_data[, i] by plant_data[, \"treatment\"]\nt = 5.5734, df = 53.756, p-value = 8.253e-07\nalternative hypothesis: true difference in means between group control and group drought is not equal to 0\n95 percent confidence interval:\n  5.834435 12.391287\nsample estimates:\nmean in group control mean in group drought \n             50.37060              41.25774 \n\n\n$seed_mass_mg\n\n    Welch Two Sample t-test\n\ndata:  plant_data[, i] by plant_data[, \"treatment\"]\nt = 11.265, df = 57.946, p-value = 3.166e-16\nalternative hypothesis: true difference in means between group control and group drought is not equal to 0\n95 percent confidence interval:\n  8.400055 12.030443\nsample estimates:\nmean in group control mean in group drought \n             30.80458              20.58934 \n\n\nWhen you are writing a for loop (especially ones more complex than the above), it can be helpful to first develop the code within the loop to more easily debug it. For example:\n\n## set the iterator variable to one of the values to be looped through\ni &lt;- dep_vars[1]\n\n## then try coding what you want to do repeatedly\ntest_result &lt;- t.test(plant_data[,i] ~ plant_data[,\"treatment\"])\ntest_result\n\n\n    Welch Two Sample t-test\n\ndata:  plant_data[, i] by plant_data[, \"treatment\"]\nt = 7.8682, df = 57.708, p-value = 1.052e-10\nalternative hypothesis: true difference in means between group control and group drought is not equal to 0\n95 percent confidence interval:\n 2.852358 4.799160\nsample estimates:\nmean in group control mean in group drought \n            12.047247              8.221488 \n\n\nThis can be helpful because R, like most programming languages, is very particular about syntax. If you had tried to use the $ operator to select columns, you would have gotten an error:\n\n## this doesn't work because i is a character value in quotes, which is incompatible with $\nt.test(plat_data$i ~ plant_data$treatment)\n\nThere are some “common pitfalls” to writing for loops, which I hope I have avoided here. You can read about them in more detail here:\nhttps://adv-r.hadley.nz/control-flow.html#common-pitfalls\n\n\n2.0.2 while loops\nwhile loops are a bit less common, but can be useful in certain contexts (mostly simulation). They follow this form:\n\nwhile (some_condition == TRUE) {\n  some_function()\n}\n\nThe first line provides a conditional statement to be evaluated at each iteration, if it is met the loop will continue to run, if it is not met the loop will close.\nThere are two uses for while loop that I have found. The first is when there is some degree of randomness in how many iterations need to be run. Let’s say for example you want to simulate a population of organisms that aggregate in groups, but you want to allow the group sizes to vary while the global population size remains the about the same. In this case, you could use a while loop:\n\n## first let's set the population size to 0\nN &lt;- 0\n\n## and create an empty vector for group size\ngroups &lt;- NULL\n\n## and a counter variable\ncounter &lt;- 1\n\n## now let's start the while loop\nwhile (N &lt; 100) {\n  ## randomly generate a group size as a pull from a poisson distribution w/ a mean of 5\n  groups[counter] &lt;- rpois(n = 1, lambda = 5)\n  ## calculate total pop size\n  N &lt;- sum(groups)\n  ## increase counter\n  counter &lt;- counter + 1\n}\n\nIf you run that code multiple times, you’ll see that you will end up with different numbers of groups with different numbers of members. This could be useful for simulation models or parametric bootstrapping. However, you may also notice that the total population size here isn’t exactly constant. To keep it constant, you could do something like this:\n\n## first let's set the population size to 0\nN &lt;- 0\n\n## and create an empty vector for group size\ngroups &lt;- NULL\n\n## and a counter variable\ncounter &lt;- 1\n\n## now let's start the while loop\nwhile (N &lt; 100) {\n  ## calculate remaining population to fill\n  to_fill &lt;- 100 - sum(groups)\n  ## randomly generate a group size as a pull from a poisson distribution w/ a mean of 5\n  ## but if it is larger than the remaining population to fill, just fill it up exactly\n  groups[counter] &lt;- min(rpois(n = 1, lambda = 5), to_fill)\n  ## calculate total pop size\n  N &lt;- sum(groups)\n  ## increase counter\n  counter &lt;- counter + 1\n}\n\nNifty!\nThe other use of a while loop that I have found is for a brute force algorithm. Basically, if you have do something complex but don’t have the time or mental energy to figure out the precise algorithm to do it, you can do it the “stupid” way. This is basically like trying every combination on a lock until it opens. Computer scientists frown on these methods for being highly inefficient, but we are computer scientists. For ecology/evolution/behavior contexts, you might use a brute force while loops to try random combinations of data or sample sets of observations with many characteristics until you find a combination/set that meets highly specific criteria that you are looking for (e.g., subsampling a large dataset such that you sample randomly but also cover a wide range of treatment levels, sampling dates, etc.).\n\n\n2.0.3 repeat loops\nrepeat loops are a very basic sort of loop that simply do something over an over again until a condition is met, then they close. Here’s the form:\n\nrepeat {\n  some_function()\n  if (some_condition == TRUE) break\n}\n\nTo me they kind of seem like a while loop formatted differently. I suppose you could add multiple “break” points for different end conditions, but I believe you can add “break” commands to any type of loop.\nLet me know if you know of cases where repeat loops are effective!",
    "crumbs": [
      "Iteration: Loops, Functions, and the purr package",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of Loops</span>"
    ]
  },
  {
    "objectID": "when_loops.html",
    "href": "when_loops.html",
    "title": "3  When to Loop?",
    "section": "",
    "text": "Now you may have often heard that you should avoid using for loops because they are slow. This isn’t strictly true; it depends how you write them. It has to do with how R uses your computer’s working memory, but the details are probably not worth getting into. Generally if you avoid the “common pitfalls” linked in the last section, you should be writing loops that are plenty fast. Also, in my personal opinion, I’m not sure how important speed is for most of our work - since we’re not developing software or data pipelines for business purposes, we are more interested in the end result and less interested in how long it took our program to get there. All this to say, don’t worry about the for loops you use being inefficient. A good guideline might be: do what you need to do now to get your results, and maybe do it a little better next time.\nHowever, there are other reasons not to use for loops that I think are more compelling, and we’ll talk about them when we talk about functions. But sometimes you just have to use loops. How can you know?\nBasically -\nYou need to use a loop when the process of one iteration depends on the outcome of previous iteration/s.\nThe while loop we used in the last section is technically an example of a case where a loop is necessary, but let’s look at another clearer ecological example: discrete population growth.\nLet’s use one common formulation of discrete logistic growth:\n\\[\nN_{t+1} = N_t *e^{r(\\frac{K-N_t}{K})}\n\\]\nWhere N is population size, r is growth rate, and K is carrying capacity.\nAs you can see, that pesky Nt is involved in the calculation of Nt+1, or in other words, the process of calculation for one iteration/timestep depends on the outcome of the previous iteration/timestep. Thus we need to use a loop:\n\n## set growth rate, r, and carrying capacity K\nr &lt;- 1\nK &lt;- 100\n\n## set number of timesteps, t, and preallocate population size vector, N\nt &lt;- 20\nN &lt;- vector(mode = \"numeric\", length = t)\nN[1] &lt;- 1\n\n## loop through timesteps and calculate population size\n## note: we are considering t = 1 as initial pop size\nfor (i in 1:(t - 1)) {\n  N[i+1]  = N[i] * exp(r * ((K-N[i])/K))\n}\n\n## plot the output                                 \nplot(1:t, N, type = \"o\", xlab = \"t\")\n\n\n\n\n\n\n\n\nThis relatively simple loop is what powers this web app:\nhttps://cwojan.shinyapps.io/discrete_logistic_growth/\nCool!",
    "crumbs": [
      "Iteration: Loops, Functions, and the purr package",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>When to Loop?</span>"
    ]
  },
  {
    "objectID": "functions.html",
    "href": "functions.html",
    "title": "4  Functions",
    "section": "",
    "text": "So we just went over the contexts when you need to use loops, but what else can you do when looping isn’t necessary (i.e., the process of one iteration does not depend on previous iterations)?\nYou can write your own functions and use functionals to iterate them! We’ll talk about functionals in the next section, but for now let’s go over how to write functions and why.\n\n4.0.1 How to Write Functions\nYou are all familiar with functions in general, we’ve been using them all throughout this workshop! However, the ones we’ve been using are premade for us. Now, we will write our own.\nA function is made up of a couple of things: a name, one or more arguments, and body of code. You can make one with the following form:\n\nnew_function &lt;- function(some_argument, some_default = \"default\"){\n  output &lt;- what_the_function_does(some_argument, default)\n  return(output)\n}\n\nWe start by providing our function name, “new_function”, and we assign the output of the “function” function to that name as an object. (That sentence had a alot of “functions” in it…). Within the parentheses of the “function” function we can provide what arguments we want our new_function to have. We can set a default value for an argument by setting an argument = to some value or data structure. Finally, we provide what the function does in the brackets after the end parentheses. We can set what new_function’s output will be with the return() statement.\nNow let’s do a working example, using our fake plant data that we used with a for loop earlier. Here’s the code to generate it again:\n\n## create a data frame with 60 total plants and\n## -two treatment levels, control and drought\n## -plant heights, masses, and seed masses sampling from a normal distribution\nplant_data &lt;- data.frame(treatment = rep(c(\"control\",\"drought\"), each = 30),\n                         height_cm = rnorm(n = 60, mean = rep(c(12,8), each = 30), sd = 2),\n                         dry_biomass_g = rnorm(60, mean = rep(c(50, 40), each = 30), sd = 6),\n                         seed_mass_mg = rnorm(60, mean = rep(c(30, 20), each = 30), sd = 4))\n\nNow let’s create a function to do a t-test for a given dependent variable. But this time instead of creating a list of statistical output, let’s make it output just a few numbers of interest: the effect size (mean difference in this case), the 95% confidence interval, and the p value.\n(this can be done with functions in the broom package, but it is a simple task that’s good for demonstration purposes).\nInstead of jumping right into the function, I’m going to figure out how to pull out those values, and then make the function (for easier debugging)\n\n## let's imagine a function that takes three arguments: \n## dat for the data frame, treatment for the categorical column,\n## and measurement for the dependent variable of interest\n## let's set them to play with:\ndat &lt;- plant_data\ntreatment &lt;- \"treatment\"\nmeasurement &lt;- \"height_cm\"\n\n## now let's put those into a t_test\ntest_result &lt;- t.test(dat[,measurement] ~ dat[,treatment])\n\n## we can pull out values with $, for example\ntest_result$p.value\n\n[1] 1.163367e-13\n\n## so make it a dataframe\nclean_result &lt;- data.frame(mean_diff = diff(test_result$estimate),\n                           ci_lwr = test_result$conf.int[1],\n                           ci_upr = test_result$conf.int[2],\n                           p_val = test_result$p.value)\nclean_result\n\n                      mean_diff   ci_lwr   ci_upr        p_val\nmean in group drought -4.355121 3.459396 5.250847 1.163367e-13\n\n\nThat looks like what we want! There is a inaccurate row name, but we can ignore that because it won’t really affect anything. Now let’s write it as a function!\n\n## let's name our function quick_t_test and give it our three arguments\nquick_t_test &lt;- function(dat, treatment, measurement){\n  ## do t test\n  test_result &lt;- t.test(dat[,measurement] ~ dat[,treatment])\n  ## pull out summary\n  clean_result &lt;- data.frame(mean_diff = diff(test_result$estimate),\n                           ci_lwr = test_result$conf.int[1],\n                           ci_upr = test_result$conf.int[2],\n                           p_val = test_result$p.value)\n  ## return the clean_result as output from the function\n  return(clean_result)\n}\n\nNote: the “return” command isn’t strictly necessary here, because custom R functions will default to returning the last object created. However, I like to be explicit, especially when you create multiple object in a function.\nNow let’s test out our function!\n\n## use quick t test on our fake data\nquick_t_test(dat = plant_data, treatment = \"treatment\", measurement = \"height_cm\")\n\n                      mean_diff   ci_lwr   ci_upr        p_val\nmean in group drought -4.355121 3.459396 5.250847 1.163367e-13\n\n## try another variable\nquick_t_test(dat = plant_data, treatment = \"treatment\", measurement = \"dry_biomass_g\")\n\n                      mean_diff  ci_lwr   ci_upr        p_val\nmean in group drought -11.62666 8.54105 14.71227 4.562067e-10\n\n\nIt works! In the next section, we will apply this function iteratively with functionals, and the true power of functions will be apparent.\nOne more thing to note about functions is the distinction between local and global variables. Within the body of the function, any variable you create is local to the function, so only exists while the function is running. After it completes, you will only have access to whatever you’ve returned. Global variable are what exist outside of the function in your environment. You can refer to them inside a function, but it makes the function less versatile.\n\n\n4.0.2 Benefits of Writing Functions\nFunctions can be an efficient way to write your code for a variety of reasons. As mentioned before, some people prefer iterating functions with functionals for processing speed reasons, but I don’t think that is as important for us, and in many cases there may not be a speed difference. Instead, I think writing functions is helpful because:\n\nThey can be easier to read. Looking back at code with a complicated nested for loop can be tough to parse, but code organized into functions can be easier to get a handle on.\nThey can be faster to write. I find myself getting things done quicker when I use functions - loops seemed to take longer to write and troubleshoot.\nThey can be transportable. Once you’ve written a generic function, you can copy and paste it into any old script where it would be useful, while it would be harder to do that with a loop.\nThey can make organizing large projects easier. Often people will create one script with all the functions for a certain analysis, and then other scripts where the analysis is run and output produced. This can be easier to keep track of and lead to shorter scripts to scroll through.\nThey can make your code modular. You can make your script a system of components that work together, functions can call other functions, and bugs are usually isolated to individual components.",
    "crumbs": [
      "Iteration: Loops, Functions, and the purr package",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "purrr.html",
    "href": "purrr.html",
    "title": "5  Functionals with purrr",
    "section": "",
    "text": "Now that we’ve written a function, let’s use it efficiently with functionals. Functionals are functions that take other functions as one of their arguments, and then can apply that function a number of times or to a range of values (much like a loop!). Base R has the “apply” family of functionals, including lapply and sapply, but I’ve found those difficult to learn because they have inconsistent syntax and behavior. Instead, we will use the “map” functionals from the “purrr” package. It’s part of the tidyverse, so you likely already have it installed. If not, use this code:\n\ninstall.packages(\"purrr\")\n\nNow, we can load the package, and make sure we have our fake plant data and quick_t_test function in our environment.\n\nlibrary(purrr)\n\nplant_data &lt;- data.frame(treatment = rep(c(\"control\",\"drought\"), each = 30),\n                         height_cm = rnorm(n = 60, mean = rep(c(12,8), each = 30), sd = 2),\n                         dry_biomass_g = rnorm(60, mean = rep(c(50, 40), each = 30), sd = 6),\n                         seed_mass_mg = rnorm(60, mean = rep(c(30, 20), each = 30), sd = 4))\n\nquick_t_test &lt;- function(dat, treatment, measurement){\n  ## do t test\n  test_result &lt;- t.test(dat[,measurement] ~ dat[,treatment])\n  ## pull out summary\n  clean_result &lt;- data.frame(mean_diff = diff(test_result$estimate),\n                           ci_lwr = test_result$conf.int[1],\n                           ci_upr = test_result$conf.int[2],\n                           p_val = test_result$p.value)\n  ## return the clean_result as output from the function\n  return(clean_result)\n}\n\n\n5.0.1 The Basic map Functional\nNow let’s use the map functional to iterate our quick_t_test function over each of our dependent variables. We simply provide it what we want to iterate over and then we provide the function we want it to do as arguments. Let’s go over a simple example first, making vectors of randomly generated numbers of different lengths, 1 through 5.\n\nmap_results &lt;- map(.x = 1:5, ## iterate over .x\n                   .f = rnorm) ## and do .f\n\n## we get a list of vectors\nmap_results\n\n[[1]]\n[1] -0.4868758\n\n[[2]]\n[1]  0.9899007 -1.3686971\n\n[[3]]\n[1] -0.05629731 -0.02063684 -1.02779153\n\n[[4]]\n[1] -0.4724920 -0.9973225  0.7358653  0.2723169\n\n[[5]]\n[1]  0.51328884 -0.18243314  0.06185269  1.03647366 -0.40712528\n\n\nOne thing that is implicitly going on here is that 1:5 is being plugged into the first argument of rnorm by default, which is the number of observations to generate. The mean and sd default to 0 and 1 respectively (as indicated in the help doc for rnorm). However, our function has three arguments with no defaults, so we will need to supply those arguments and values in the map functional to do a quick t test for each of three variables:\n\n## quick t test each dependent variable\nttest_results &lt;- map(.x = c(\"height_cm\", \"dry_biomass_g\", \"seed_mass_mg\"),\n                     .f = quick_t_test,\n                     dat = plant_data, treatment = \"treatment\")\n\n## show results\nttest_results\n\n[[1]]\n                      mean_diff   ci_lwr   ci_upr        p_val\nmean in group drought -3.622931 2.724816 4.521046 4.779452e-11\n\n[[2]]\n                      mean_diff   ci_lwr   ci_upr        p_val\nmean in group drought  -10.3419 7.066072 13.61773 4.343477e-08\n\n[[3]]\n                      mean_diff   ci_lwr  ci_upr        p_val\nmean in group drought -10.53933 8.244366 12.8343 6.389394e-13\n\n\nHowever, this list isn’t super nice to look at. We could bind the rows into a data frame (with list_rbind or dplyr::bind_rows), or we could just made a data frame in the first place with map_dfr, which will always output a data frame (well, a tibble). Note that map_dfr is technically “superseded” because it requires the dplyr package to be installed, but it still works fine if you do.\n\n## quick t test each dependent variable\nttest_df &lt;- map_dfr(.x = c(\"height_cm\", \"dry_biomass_g\", \"seed_mass_mg\"),\n                    .f = quick_t_test,\n                    dat = plant_data, treatment = \"treatment\")\n\n## add a label column\nttest_df$dep_var &lt;- c(\"height_cm\", \"dry_biomass_g\", \"seed_mass_mg\")\n\n## show results\nttest_df\n\n                           mean_diff   ci_lwr    ci_upr        p_val\nmean in group drought...1  -3.622931 2.724816  4.521046 4.779452e-11\nmean in group drought...2 -10.341902 7.066072 13.617732 4.343477e-08\nmean in group drought...3 -10.539333 8.244366 12.834299 6.389394e-13\n                                dep_var\nmean in group drought...1     height_cm\nmean in group drought...2 dry_biomass_g\nmean in group drought...3  seed_mass_mg\n\n\nMuch nicer right? (just ignore those row names, we could remove them if we wanted). There are map functions that specifically output all sorts of data structures, like vectors of specific data types (e.g., map_chr for strings, map_int for integers). There is even a map functional that provides no output but iteratively performs a function: walk(). You could use walk when you want to iteratively draw plots or save files.\nOne thing that is also helpful is that you can write a function within a map functional, if you just need to do something over and over again but don’t need to use the function elsewhere. So we could have done this:\n\nttest_df2 &lt;- map_dfr(.x = c(\"height_cm\", \"dry_biomass_g\", \"seed_mass_mg\"),\n                     .f = function(x){\n                       ## do t test\n                       test_result &lt;- t.test(plant_data[,x] ~ \n                                             plant_data[,\"treatment\"])\n                       ## pull out summary\n                       clean_result &lt;- data.frame(mean_diff = diff(test_result$estimate),\n                                                  ci_lwr = test_result$conf.int[1],\n                                                  ci_upr = test_result$conf.int[2],\n                                                  p_val = test_result$p.value)\n                       ## return the clean_result as output from the function\n                       return(clean_result)\n                      })\n\nWe could have also done this with our pre-made function to deal with the arguments more explicitly:\n\nttest_df3 &lt;- map_dfr(.x = c(\"height_cm\", \"dry_biomass_g\", \"seed_mass_mg\"),\n                     .f = function(x){\n                       quick_t_test(dat = plant_data, treatment = \"treatment\",\n                                    measurement = x)\n                     })\n\n\n\n5.0.2 Iterating over Two Ranges with map2\nYou can also iterate over two ranges of values with map2 functionals, or many with pmap functionals. Let’s try it with our data by calculating the covariance between each pair of our dependent variables (there are likely other functions for this, but again, this is just a demo):\n\n## first let's find the pairs of our variables with combn\nvar_coms &lt;- combn(x = c(\"height_cm\", \"dry_biomass_g\", \"seed_mass_mg\"), m = 2)\nvar_coms\n\n     [,1]            [,2]           [,3]           \n[1,] \"height_cm\"     \"height_cm\"    \"dry_biomass_g\"\n[2,] \"dry_biomass_g\" \"seed_mass_mg\" \"seed_mass_mg\" \n\n## we can use the two rows as our iterating ranges\n\n## use map2_dbl to coerce to numeric vector\nvar_covs &lt;- map2_dbl(.x = var_coms[1,], .y = var_coms[2,],\n                     .f = function(x, y){ ## use a wrapper function to set the data frame\n                      cov(plant_data[,x], plant_data[y])\n                     })\nvar_covs\n\n[1]  8.044473 10.125000 26.044787\n\n\nHere we didn’t just use “cov” because we wanted to pull the data from the plant_data data frame, so we used a “wrapper” function so that we could more precisely set the arguments of cov().\nWe can put all of our info together like so:\n\nplant_covs &lt;- data.frame(var1 = var_coms[1,],\n                         var2 = var_coms[2,],\n                         cov = var_covs)\n\nplant_covs\n\n           var1          var2       cov\n1     height_cm dry_biomass_g  8.044473\n2     height_cm  seed_mass_mg 10.125000\n3 dry_biomass_g  seed_mass_mg 26.044787\n\n\nWe could have also plugged the map functional right into our data.frame construction. If you are familiar with dplyr and use mutate, you can mutate new columns using map as well!\n\n\n5.0.3 Concluding Remarks (that sounds too formal…)\nSince the above demonstrations are relatively simple, you may be skeptical of the advantages of writing custom functions to iterate with functionals like map. And if you prefer to use loops, just use loops! You can do a lot of cool stuff with for loops. However, I think it’s always nice to add more techniques to your “coding toolbox,” as you can solve more problems.\nParticularly, as your code gets more complex and interconnected, and your project gets larger, functions and functionals can really come in handy for keeping things organized. For example, I have a simulation project where I have a function to generate simulated landscapes, functions to look at those landscapes, a function to simulate animal movement over those landscapes, and a function that applies parasitic interactions with those animals (the animal movement function is called within this function). This way I can pinpoint where bugs might be easily and transfer my landscape generation or movement functions to other projects. Perhaps most importantly, I can use map to try generating landscapes and simulating movement under a range of different parameters. This general organizational concept could be applied to more analytical projects where you are aalyzing and plotting different datasets in different ways.\nIn the end, you have the most important opinion on how you code, so try using functionals and see how they can be best integrated into your coding!\nIf you’d like to learn more than this shallow introduction, check this link out:\nhttps://purrr.tidyverse.org/",
    "crumbs": [
      "Iteration: Loops, Functions, and the purr package",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functionals with purrr</span>"
    ]
  },
  {
    "objectID": "parallel_computing.html",
    "href": "parallel_computing.html",
    "title": "6  Parallel Computing with map",
    "section": "",
    "text": "If you want to go really fast, you can improve the performance of map functionals by using the parallel computing versions of them. Basically you can split the iterations you are doing among different R sessions or processing cores to shorten the total time to finish them all.\nTo demonstrate, I want to first make a function that is slow to run. It takes a while to calculate the distance matrix of a set of coordinates, especially if there’s a lot of them. So I will make a function that does just that (don’t worry about what actually is being done here, just that it is slow):\n\n## load purrr library for later\nlibrary(purrr)\n\n## set the only argument to be the size of the coordinate system, with a default of 1000\n## store output temporarily and then delete it to clear up memory\nlong_function &lt;- function(size = 1000){\n  temp &lt;- dist(c(1:size, 1:size))\n  rm(temp)\n}\n\n## runs without errors (defaults to size = 1000)\nlong_function()\n\nNow let’s try running this function multiple times with walk (which is a purrr functional that gives no output), and measure how much time it takes. There a fancy ways to do this with performance check packages, but a simple way is to check the time before running, and then after running, and checking the difference (you need to run the code all at once for this to work though).\n\n### run this block all at once\n## save start time\nstart &lt;- Sys.time()\n## iterate long function for 1000 iterations of the same size value\nwalk(.x = rep(1000, 1000), .f = long_function)\n## save end time\nend &lt;- Sys.time()\n## calculate runtime\nend - start\n\nTime difference of 4.987556 secs\n\n###\n\nThe time difference varies on my machine, but for me it’s usually around or above 5 seconds. Obviously that’s not terribly long, but good for demonstration purposes. If we instead chunk those 500 iterations to be performed in prralel by separate R sessions, we should be able to divide that runtime by as many sessions as you have.\nFor this we need the “furrr” package (hey it rhymes with purrr!), as well as it’s dependency “future”.\n\ninstall.packages(\"furrr\")\n\n## if it doesn't install future automatically....\ninstall.packages(\"future\")\n\nThen we need to set the “plan” to use multiple R sessions. This is basically telling the alternative map functional that we will use in the next step how to evaluate its process, sequentially or in parallel with multiple sessions (or cores, or even machines).\n\n## load furrr\nlibrary(furrr)\n\nLoading required package: future\n\n## set plan to use 5 R sessions\nplan(multisession, workers = 5)\n\nNow we can use “future_walk” to run the function for 1000 iterations in ~1/5th the time!\n\n### run this block all at once\n## save start time\nstart &lt;- Sys.time()\n## iterate long function for 1000 iterations of the same size value\nfuture_walk(.x = rep(1000, 1000), .f = long_function)\n## save end time\nend &lt;- Sys.time()\n## calculate runtime\nend - start\n\nTime difference of 2.16028 secs\n\n###\n\nThis usually runs in less than 2 seconds! Wheee! Obviously in this case, a &gt;50% reduction in time doesn’t add up to much in seconds, but when your function takes hours, you can work much faster with furrr.\nThis is a very surface level demo, but should be good enough to speed up some of your code. There is a lot of depth to this topic that I’m not equipped to speak on, so do look here for more info:\nhttps://furrr.futureverse.org/index.html\nAnd the plan function in particular is good to understand:\nhttps://www.rdocumentation.org/packages/future/versions/1.33.0/topics/plan",
    "crumbs": [
      "Iteration: Loops, Functions, and the purr package",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Parallel Computing with map</span>"
    ]
  },
  {
    "objectID": "vectorization.html",
    "href": "vectorization.html",
    "title": "7  Vectorization",
    "section": "",
    "text": "So the last thing I want to mention is the fastest way to iterate, and one that you have already done - vectorization. Many of R’s base functions are written in C, which is much faster than R, so simple iterations can be done much faster. These functions are referred to as “vectorized”, or you are basically performing vector math with them. Here is a simple example: let’s find the 1 through 6th powers of 2:\n\n## we could write a loop\nfor (i in 1:6){\n  print(2^i)\n}\n\n[1] 2\n[1] 4\n[1] 8\n[1] 16\n[1] 32\n[1] 64\n\n## or we could use a functional\nlibrary(purrr)\nmap_int(.x = 1:6, .f = function(x){2^x})\n\n[1]  2  4  8 16 32 64\n\n## or we could simply use vector math; the \"^\" function is written in C, so...\n2^(1:6)\n\n[1]  2  4  8 16 32 64\n\n\nThe third solution (which is the fastest) may have been obvious to you, but sometimes it’s not so obvious.\nConsider simulating an animal that moves randomly around an infinite grid (or perhaps simulating Brownian motion of particles). If you wanted to track that animal/particles position at each of 100 timesteps, it seems like a for loop would be your best bet. The position of the animal at one time step depends in part on its position in the last time step, right? So let’s show that:\n\n## create a matrix to keep track of positions\nanimal_coords &lt;- matrix(NA, nrow = 101, ncol = 2)\n## start our animal at the origin of the infinite grid\nanimal_coords[1,] &lt;- c(0,0)\n\n## move it 100 times\nfor (i in 1:100){\n  animal_coords[i+1,1] &lt;- animal_coords[i,1] + sample(x = c(1,0,-1), size = 1)\n  animal_coords[i+1,2] &lt;- animal_coords[i,2] + sample(x = c(1,0,-1), size = 1)\n}\n\nSo that works, and it’s plenty fast for a single run of 100 timesteps, but increase the timesteps and simulate over some parameter space and it gets lengthy. Luckily, base R has a helpful vectorized function for this: cumsum. It calculates the cumulative sum of a vector at each index. So we can also write our random walk like this:\n\n## cumulatively sum random movements for the x and y coordinate\nx_coords &lt;- cumsum(c(0, sample(c(1,0,-1), size = 100, replace = TRUE)))\ny_coords &lt;- cumsum(c(0, sample(c(1,0,-1), size = 100, replace = TRUE)))\n\n## bind those coords\nnew_animal_coords &lt;- cbind(x_coords, y_coords)\n\n(Note: for random walks across higher dimension arrays, writing a function and iterating over each axis would be advisable).\nThat method would save you a lot of time if you were running tons of simulations! Basically, we are outsourcing our for loop to C with the cumsum function. When you can, outsource iterations to C! (Although it may take some time digging around base R functions to find what you need).",
    "crumbs": [
      "Iteration: Loops, Functions, and the purr package",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Vectorization</span>"
    ]
  },
  {
    "objectID": "git_github.html",
    "href": "git_github.html",
    "title": "8  Git and GitHub",
    "section": "",
    "text": "8.1 Introduction\nThis page aims to get people started with using version control in their coding and data analysis with R, specifically using git (a computer application) and GitHub (a website).\nBy far the most useful resource for this aim is the following webpage from statistician Jenny Bryan:\nHappy Git With R\nOn this page is a shorter summary of some of the key points based on specifically how I (Chris Wojan) work with git and GitHub.",
    "crumbs": [
      "git, GitHub, Building Websites, and Copilot",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Git and GitHub</span>"
    ]
  },
  {
    "objectID": "git_github.html#introduction",
    "href": "git_github.html#introduction",
    "title": "8  Git and GitHub",
    "section": "",
    "text": "8.1.1 Why?\nWhen writing code, three things can be helpful:\n\nBacking up your scripts\nSharing your code easily\nLooking at previous versions of code in case something breaks\n\nUsing git allows you to save iterative versions of your code (and thus monitor your successive edits). Using GitHub allows you to back up your scripts online, and share your code easily with collaborators without attaching misc. files to emails.",
    "crumbs": [
      "git, GitHub, Building Websites, and Copilot",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Git and GitHub</span>"
    ]
  },
  {
    "objectID": "git_github.html#version-control-with-git",
    "href": "git_github.html#version-control-with-git",
    "title": "8  Git and GitHub",
    "section": "8.2 Version Control with git",
    "text": "8.2 Version Control with git\nOur first step is to get git installed locally on our computers. Since git is designed primarily for computer programming applications, its installation is a bit different than many applications, and the steps vary among operating systems.\n\n8.2.1 MacOS\nIf you use MacOS (like me), installing git is fairly straightforward, but there are a few ways to do it.\nNote: if you think git might already be installed on your computer, you can check by opening the Terminal in RStudio (Tools -&gt; Terminal) or through your OS (e.g. MacOS’ Terminal application), and then entering the command:\nwhich git\nI personally have installed Homebrew, which is a tool that allows you to install useful applications and code packages. You can install Homebrew with the traditional Mac .pkg installation process from their GitHub Repository. Alternatively, you can open the Terminal application on your Mac and input the following command:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\nWith Homebrew installed, you can simply open the MacOS Terminal application or Terminal in RStudio (Tools -&gt; Terminal) and input the following command:\nbrew install git\nAlternatively, Apple features git in its “xcode” set of command line tools, you can install these (including git) with this command in your Terminal:\nxcode-select --install\n\n\n8.2.2 Windows\nI am personally less adept with git on Windows, but you should be able to download git through a typical installer from these pages:\nGit For Windows\nor\nWindows git Download\nBoth of those should come with a git Bash Shell, where you can input command line git actions if needed. Windows doesn’t have a simple shell/terminal situation like MacOS does unfortunately. However, you should be able to check if you have git installed in Command Prompt, VirtualShell, or something else (?) with\nwhich git\n\n\n8.2.3 Linux\nIf you are using Linux, you know more than me.",
    "crumbs": [
      "git, GitHub, Building Websites, and Copilot",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Git and GitHub</span>"
    ]
  },
  {
    "objectID": "git_github.html#github",
    "href": "git_github.html#github",
    "title": "8  Git and GitHub",
    "section": "8.3 GitHub",
    "text": "8.3 GitHub\nWhile git can be used locally for version control, it is arguably most effective when used in conjunction with an online repository. GitHub is the most popular and well-documented.\nYou can register an account for free here:\nhttps://github.com\nThe aforementioned Jenny Bryan recommends choosing a simple username that features your name somehow, and I do too as you’ll likely be using this account in conjunction with your scientific publications.\nIn addition, the username you choose will be the prefix of your personal website if you choose to make one with GitHub.\nAlso, as a University of Minnesota student, you can get access to Github Education through this page:\nGitHub Education\nThis comes with a variety of features, but the only one I’ve used is Copilot, which we’ll go over in a later page.\nWith a GitHub account, you can make an unlimited number of “repositories”, which are basically folders hierarchies for code (in truth, this is based on how git works without GitHub). These repositories can be private or public, and you can switch visibility after you’ve made one (e.g., making a repo public when submitting a manuscript). R Projects in RStudio are designed to match and work as git repositories.",
    "crumbs": [
      "git, GitHub, Building Websites, and Copilot",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Git and GitHub</span>"
    ]
  },
  {
    "objectID": "git_github.html#connecting-in-rstudio",
    "href": "git_github.html#connecting-in-rstudio",
    "title": "8  Git and GitHub",
    "section": "8.4 Connecting in RStudio",
    "text": "8.4 Connecting in RStudio\nNow you should have git installed on your computer, and GitHub account where you can back up and share your code. While you can use git in the Terminal/Shell to send files to GitHub, it is easier for beginners (and me) to use RStudio to connect things.\n\n8.4.1 Configuring\nThere are also some handy R packages to make things easy that we can use. The first is “usethis”, which has various utilities for managing coding projects in R.\ninstall.packages(\"usethis\")\nOne nifty function is the ability to configure your git installation through R, i.e. setting your name and GitHub account-related email:\nlibrary(usethis)\nuse_git_config(user.name = \"Jane Doe\", user.email = \"jane@example.org\")\nI believe this is a necessary step to get things working, but I’m not absolutely positive. It’s easy enough though!\nNext, there is the very useful “gitcreds” package (this one will likely get periodic use, as you will see).\ninstall.packages(\"gitcreds\")\nThis will take us to how we can “log in” to GitHub through RStudio. To do this, we will need a Personal Access Token or PAT to authorize RStudio to do git actions. You can do this through usethis, but I think it is more intuitive to do it on the GitHub website.\nTo do so, when logged in on GitHub, click your profile picture in the upper right (probably a weird collection of pixels), and scroll down to Settings. Once there, scroll down to “Developer Settings” on the left sidebar. Click that and then Personal Access Tokens again on the left sidebar, and “Tokens (classic)” in the dropdown. There, you can click Generate New Token (again choose “classic”).\nWhen generating a new token, you’ll be given a bevy of options, the first of which is a note. I usually just call it the month and the year.\nThen you set how long until it expires. You can set it to never expire, which GitHub does not recommend, but I just go with 90 days myself (after which you will just repeat the process we are doing now).\nYou will also set the scope of the token. For our purposes click the header checkboxes for repo, workflow, and user.\nThen click generate token, and you’ll be given a long sequence of characters that you should copy to your clipboard, as you won’t be seeing it again. If you close the window or something beforehand, you can just generate a new token though.\nNow, with PAT copied, we can run the following code in R:\ngitcreds::gitcreds_set()\nIt will then prompt you to set or replace your credentials. You can use your GitHub username, and the PAT you generated as the password.\nNow you should be able to communicate from RStudio to GitHub!\n\n\n8.4.2 Creating a Repo\nTo test out our connection, let’s make a repository! The simplest way, and the way I usually do this is by making a repository on GitHub first.\nTo do so, be logged in to GitHub and click the green “New” button near repositories on the left of your dashboard page.\nThe page it takes you to will have a few options. The most important is the repository name. For this purpose it doesn’t really matter, as you can delete this repository after testing.\nYou can also set if it is private or public, add a readme, select a gitignore template (more on this later), and set the license, but you don’t need to bother with those for now.\nWhen you hit create, you’ll be taken to a new repo page. If you did not create a Readme, it will just be a setup page where you can copy the HTTPS link easily (which you should do!).\nAlternatively, with a readme file, you’ll have a more traditional repo page, where you can click the green “Code” button to copy the HTTPS link to the repo.\nIn either case, the link should look like “https://github.com/your-username/your-repo.git”.\nWith this copied, head to RStudio, and click File &gt; New Project, or New Project from the project tab in the upper right.\nIn the dialog box that pops up, select “Version Control” then “git”, and paste in your repository link in the “Repository URL” field. Take note of the directory where this project is being saved.\nWith the new project opened, you can edit the Readme.md file, or create a new .R file, and save these change locally in RStudio. Do something like this.\nYou should notice that in the upper right pane of RStudio, there is a git tab. There, any new saved change you have made should show up. You can click the check box under “Staged” to add these changes to a potential “commit”. A commit is a locally stored snapshot of a repository that you can create whenever you choose to.\nWith your changes staged, click the Commit button in the git tab, and you’ll see a dialog box where you can add a message for the commit, summarizing what changes have been made. You can also track what changes you’ve done. Then you can click commit and close the window.\nNow you can “push” these changes to your GitHub repository. Remember, commits are local to wherever you are, but can be pushed or pulled elsewhere. You can push your commits from your computer to GitHub, and you can pull commits made elsewhere from GitHub to your computer.\nIn the git tab, there are “Push” and “Pull” buttons. If you are ever working collaboratively, it can be good practice to pull before you push everytime. If you are just backing up and sharing your own code, you can just push from RStudio to GitHub when needed. Click “Push” to send your commit to GitHub.\nIf you refresh the repository’s page on GitHub, you should see the files you made or edited in RStudio there. Woohoo!\nYou can also make edits to things on GitHub and then “Pull” them to Rstudio in the git tab, but that isn’t a common thing to do at least in my experience. Pulling will mostly be relevant if you are working on a git repo with others or by yourself on multiple computers.",
    "crumbs": [
      "git, GitHub, Building Websites, and Copilot",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Git and GitHub</span>"
    ]
  },
  {
    "objectID": "organizing_repositories.html",
    "href": "organizing_repositories.html",
    "title": "9  Organizing Repositories",
    "section": "",
    "text": "9.1 Introduction\nIn the previous section, we went over getting git installed and connecting with GitHub. As we did that, we introduced the idea of git repositories. Here, we will go into a bit more detail about them.\nRepositories can be thought of as a collection of related files, much like a folder or directory on your computer (with or without subfolders). As we have discussed, with git we can save versions of this collection of files at different time points. This is like the the version history on a Google Doc, but beyond the scope of one document to a whole collection of files.\nRepositories can take many forms (this website you are reading is one!). In Ecology, Evolution, and Behavior, they are often R Projects, or projects based in Python or MatLAB, or perhaps other languages, or a mixture.\nWhile a git repository at its most basic is simply a local folder, it makes most sense in our context to talk about them as a shared entity between your local computer and the GitHub website.",
    "crumbs": [
      "git, GitHub, Building Websites, and Copilot",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Organizing Repositories</span>"
    ]
  },
  {
    "objectID": "organizing_repositories.html#repository-structure",
    "href": "organizing_repositories.html#repository-structure",
    "title": "9  Organizing Repositories",
    "section": "9.2 Repository Structure",
    "text": "9.2 Repository Structure\nOn this page, we’ll talk about the structure of a repository as an R Project built with RStudio.\nIf you are unfamiliar with R Projects in general, they are a useful way to organize code and data related to a given research project. At the very least, one consists of a .Rproj file with the project name inside of a folder on your computer named the same thing. In the folder with the .Rproj file, you can create subfolders, R scripts, and other relevant files.\nOne of the great thing about an R Project is its directory detection - when you have an R Project open, the working directory that it will read files from and write files to is the same as the folder that the .Rproj file is in. IF you want to read or write to a subfolder, you can simply add “/subfolder_name/” to your read or write function’s name or directory argument.\nOn your computer, a research project’s repository might often look something like this:\n\nproject_name\n\nproject_name.Rproj\n/code\n\nscript.R\nother_script.R\n\n/data\n\ndata.csv\n\n/figures\n\nfigure1.tiff\nfigure2.tiff\n\nREADME.md\n.gitignore\n\n\nIn such a repo, the scripts would likely read data from the “/data” folder, and write figures to the “/figures” folder.\nYour project might also feature a .Rhistory file that logs the R code that you run into a text file.\nThere are two other important files here, the first is the .gitignore file which we will go into now, and the readme file which we’ll talk about afterwards.",
    "crumbs": [
      "git, GitHub, Building Websites, and Copilot",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Organizing Repositories</span>"
    ]
  },
  {
    "objectID": "organizing_repositories.html#gitignore",
    "href": "organizing_repositories.html#gitignore",
    "title": "9  Organizing Repositories",
    "section": "9.3 .gitignore",
    "text": "9.3 .gitignore\nNow you may have noticed that I referred to the above R Project / Repository as on your computer. This is because the files in a project on your computer will generally be more inclusive than those on GitHub. GitHub is not meant as a data storage solution, so it is best to limit what is stored on GitHub to only text files - i.e. scripts of code or markdown files.\nThis asymmetry is where the .gitignore file comes in. It is a simple text file the lists the files and folders in your local repository that you don’t want to “push” to GitHub. This file is read by git, which ignores those files for commits and pushes in the git tab of RStudio (or elsewhere, like in the Terminal).\nYou can edit the .gitignore file in RStudio by opening it through the Files tab in the lower right pane. It will likely have some things already listed if you set a template .gitignore when creating your repo, or from when you created the R project itself. These include:\n\n.Rproj.user\n.Rhistory\n.RData\n.Ruserdata\n\nYou can add files and folders to this document on new lines. I general recommend that you add any subfolders of data or figures, although there may be some small output .csv files that you may want on GitHub in certain situations.\nNote: MacOS will create a .DS_Store file to your project/repo if you open it in Finder, so you may as well add “.DS_Store” to your .gitignore file.\nHere is an example repository for a manuscript I have in review:\nhttps://github.com/cwojan/spatially_aggregated_parasite\nOn the repo page, you can see there is an .Rproj file, a set of .qmd files (these are Quarto Markdown files, which is an alternative way to write R code with more documentation), and a .R script. There is also a README.md, a .gitignore, and an /old_misc_files folder.\nYou can click the .gitignore file and see that I have ignored three folders: /data, /sim_output, and /figures.\n/data and /sim_ouput contain .rds files and .csv files featuring simulation data, and some of them are rather large. /figures includes figures in high quality tiff format, so these are also large files. These folders are of course located on my computer in my R Project folder.\nYou can of course backup these types of folders that you are not sending to GitHub using Google Drive or what have you, but note that if you backup a git repo on Google Drive, your “Recent Files” tab will be filled with weirdly named config files when you do a lot of commits.",
    "crumbs": [
      "git, GitHub, Building Websites, and Copilot",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Organizing Repositories</span>"
    ]
  },
  {
    "objectID": "organizing_repositories.html#readme-files",
    "href": "organizing_repositories.html#readme-files",
    "title": "9  Organizing Repositories",
    "section": "9.4 Readme files",
    "text": "9.4 Readme files\nThe other important file that often goes along with repositories is the Readme file. This is where you can decide how to describe the project to anyone who might need to know about it, including what your aim is, what certain scripts do, etc.\nIn the example repo above, I provide a broad overview of what the researrch project is, and how someone would go about recreating my simulations with the code provided.\nI then used GitHub Copilot to generate a more detailed description, which I’m not sure on the usefulness of.\nIn any case, a Readme file is always a good idea for repositories that are going to be shared with collaborators or are part of a manuscript publication.",
    "crumbs": [
      "git, GitHub, Building Websites, and Copilot",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Organizing Repositories</span>"
    ]
  },
  {
    "objectID": "building_webpages.html",
    "href": "building_webpages.html",
    "title": "10  Building GitHub Websites with RStudio",
    "section": "",
    "text": "10.1 Introduction\nOne really cool thing you can do with a GitHub repository is turn it into a “GitHub Page” on the web, and RStudio provides built-in, intuitive ways to do so.\nBefore we get started, it is important to be familiar with “Quarto Markdown Files”, which were referenced in the last section. These are similar to R Markdown files which you may be familiar with, but are compatible with other languages (like Python), and are generally more supported by modern documentation and interfaces these days.\nWith Quarto documents, you can document and organize your code in ways that can be more clunky with pure comments. In addition, you can render these files to HTML and PDF formats, which allows you to share descriptive text with embedded code and figures. It also allows you to create HTML pages that can be published to the web without actually knowing HTML, through RStudio.\nWe will talk about two ways to do that: making your own personal webpage with your github account, and publishing a web book. The website you are reading is a web book built with Quarto documents in RStudio and published through GitHub Pages.\nBefore we get into it, the Quarto file format is extremely well-documented in detail here:\nhttps://quarto.org/\nYou can also find more info on GitHub Pages here:\nhttps://pages.github.com/\nWhat follows is a brief overview of how I (Chris Wojan) have approached using Quarto to publish websites.",
    "crumbs": [
      "git, GitHub, Building Websites, and Copilot",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Building GitHub Websites with RStudio</span>"
    ]
  },
  {
    "objectID": "building_webpages.html#personal-webpages",
    "href": "building_webpages.html#personal-webpages",
    "title": "10  Building GitHub Websites with RStudio",
    "section": "10.2 Personal Webpages",
    "text": "10.2 Personal Webpages\nWhile you can make websites for an unlimited number of your project repositories, with your free GitHub Account you can make one special website that is simply username.github.io. Here is mine:\nhttps://cwojan.github.io/\nAnd here is the repository that underlies it:\nhttps://github.com/cwojan/cwojan.github.io\n\n10.2.1 Setup\nThe key thing here is that you create a repository on GitHub that is named “[your_username_here].github.io”. The simplest way to do this is to make a repository on GitHub itself and name it that, then “clone” it to an RStudio Project on your computer (as we did in an earlier section). However, this will lead to you needing to fill your repository with the requisite files for website publishing with Quarto.\nAn alternative method, the one I used, is to make a new R Project in RStudio with a Quarto Website template. To do so in RStudio, click New Project &gt; New Directory &gt; Quarto Website. Then set the directory you want to save your site in. In “Directory name”, type “[your_username_here].github.io” (with your respective username as the prefix). Also, check “Create a git repository”.\nThe project that is then created has the basic building blocks of a Quarto site:\n\n_quarto.yaml\n\nThis file is the backbone and configuration of your site\n\nstyles.css\n\nThis file will alter the appearance of your site, but will probably remain blank if you don’t edit it yourself with your own CSS skills.\n\nindex.qmd\n\nthis is a Quarto Document that serves as the homepage of your site\n\nabout.qmd\n\nthis is a second page of your website, that can be “about” you\n\n.gitignore\n[project_name].Rproj\n\nBefore we dig into building your site, let’s make sure we can connect it to GitHub, since right now it only exists on your computer.\nThe simplest way to do this is with the aforementioned “usethis” package in R. Otherwise you’ll need to use shell/terminal commands.\nIn your new project, simply run the following in your R console:\nusethis::use_github()\nIf your git credentials are set as we did in prior sections, this will create a new repo of the same name as your local repo on GitHub and connect them together. If you named it correctly, this should then work for your special GitHub URL.\nTo test things out, make some edits to the index.qmd or about.qmd, save and commit them, then push them. Check to make sure they show up on your repo on GitHub.\nNow there’s a few steps to do before publishing (in addition to of course filling out your website):\nFirst, the simplest publishing method is to publish from a subfolder of rendered HTML in your repository. So first create a subfolder in your repo called “docs”. Then add “output-dir: docs” to your _quarto.yaml file, indented under the “project:” heading, after “type: website”.\nSecond, GitHub Pages uses Jekyll as a tool to build sites by default, but since we are using Quarto, we need to tell GitHub not to use Jekyll. To do this we just need to create a blank file called “.nojekyll”.\nIn the Terminal tab of the lower left pane in RStudio, enter\nMacOS (and probably Linux too):\ntouch .nojekyll\nWindows:\ncopy NUL .nojekyll\nThese commands create that file.\nFinally, with the .nojekyll file pushed to the repo on GitHub, you will want to go into the repo’s Settings (available along the top of the repo’s base page), click “Pages”, and make sure that the “Build and deployment” section is set to “Source: Deploy from a branch” and “Branch: main /docs”. If you build you site now, there won’t be anything because your docs folder is empty. You will need to render HTML files to that folder in RStudio before you have a site to publish.\n\n\n10.2.2 Filling in and Editing your Website\nMaking your website will begin and revolve around the _quarto.yaml file. You can use it to add pages and change the look and theme of your site.\nIn that file, there should be a “website:” header, under which there are indented sections relating to the site’s title, navigation method, and the pages. You can add pages by creating a new line under the “- about.qmd” line, and then creating a file with that name and editing it.\nThere is also a “format:” header, under which you can edit the look of the site. The easiest thing to do is edit the text after “theme:”. Quarto works with the Bootswatch set of themes you can see here:\nhttps://bootswatch.com/\nThe default is “cosmo”, but you can switch to any that are shown. I use “minty” for my website =).\nYou can also edit beyond those themes within the yaml or in a .css file, depending on your skills and desire to tweak things.\nMore details on how to edit how your website works can be found here:\nhttps://quarto.org/docs/websites/\nAnd more info on HTML construction and theming can be found here:\nhttps://quarto.org/docs/output-formats/html-basics.html\nhttps://quarto.org/docs/output-formats/html-themes.html\nFeel free to look at my website’s repo for very basic examples!\n\n\n10.2.3 Publishing Your Site\nTo publish your site, you’ll first need to render your collection of Quarto documents to HTML/CSS/JavaScript, which is as easy as a click of a button!\nUnder the “Build” tab in the upper right pane of RStudio, there should be a “Render Website” button. Click that, and RStudio will start filling the “docs” folder in your repo with rendered website files.\nOnce that is done, you’ll want to push your changes to GitHub. However, there may be many files in your git tab to stage before committing. To save time, you can use the following command in the Terminal to ready all changed files in your repo for committing:\ngit add .\n“git add” is the shell command for staging files, and “.” basically refers to all files.\nAll the files in your git tab should now have Staged checked, so you can go ahead and click Commit, and add a message like “initial site build” or something like that. Once committed, Push your commit to GitHub.\nThen, on GitHub, navigate to the Pages subtab in your repo’s settings again, and click the button to publish your site (assuming it knows to publish from the docs folder).\nWith that, a hyperlink should show up taking you to your site. Nice!\nWhen you make changes to your site’s Quarto files or yaml, you’ll need to rebuild it before pushing it, but then it should automatically republish those changes in a few minutes.\nNote: there are many other ways to publish websites with RStudio and Quarto, but this is just one simple way.",
    "crumbs": [
      "git, GitHub, Building Websites, and Copilot",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Building GitHub Websites with RStudio</span>"
    ]
  },
  {
    "objectID": "building_webpages.html#other-websites-web-books",
    "href": "building_webpages.html#other-websites-web-books",
    "title": "10  Building GitHub Websites with RStudio",
    "section": "10.3 Other Websites, Web Books",
    "text": "10.3 Other Websites, Web Books\nWhile personal websites are a common desire for folks, others might also consider publishing other repositories.\nYou can make a GitHub page for any repository you have, so you could make a website for a research project or manuscript with R code built-in to show tables and figures. To do this, you could follow similar steps as for building your personal webpage (create a Quarto Website R Project in RStudio, and then create a connected repo on GitHub with usethis), but simply name it whatever you wish instead of your specific username plus github.io. The setup and publishing steps are virtually identical.\nYou can also publish web books for educational purposes, like this one. In this case, you can start an R Project in RStudio with the “Quarto Book” template. This comes with many nifty features, like a well organized sidebar of chapters, and cross-referencing abilities. This website is a Quarto Book, and here is another example that I have made for Cedar Creek interns doing research projects:\nhttps://cwojan.github.io/ccesr_intern_hub/\nThere is a ton of info on writing web book with Quarto here:\nhttps://quarto.org/docs/books/\nIf you are interested in contributing to this book with helpful computational/quantitative resources for EEB folks, feel free to reach out to me (Chris Wojan) and I can share the repo with you so we can collaborate!",
    "crumbs": [
      "git, GitHub, Building Websites, and Copilot",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Building GitHub Websites with RStudio</span>"
    ]
  },
  {
    "objectID": "copilot.html",
    "href": "copilot.html",
    "title": "11  GitHub Copilot",
    "section": "",
    "text": "11.1 Introduction\nWhen we went over signing up for a GitHub account, I mentioned how you can get access to GitHub Education by verifying your student status at UMN. There are many features to GitHub Education, most of which I have not used. The one I have used, and found somewhat useful, is GitHub Copilot. Copilot is a Large Language Model (commonly referred to as AI) built on the GPT framework specifically fine-tuned for computer programming. You can use it to answer coding questions specific to your GitHub repositories, as well as interactively while you are coding to solve problems.\nOf course, there are ethical concerns to AI usage. Environmentally, it takes a lot of energy to train these models (although new developments seem to be reducing that consumption…). Philosophically, there are unresolved questions regarding the morality and legality of how LLMs have used web materials, oftentimes copyrighted materials, to “learn”. For many, these concerns are a strong deterrent from using AI, which is totally fair!\nIn the specific context of Copilot, I can’t say what it’s environmental footprint has been, but I can say that there are some settings you can use to mitigate some of the concerns regarding the web content used for code suggestions.",
    "crumbs": [
      "git, GitHub, Building Websites, and Copilot",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>GitHub Copilot</span>"
    ]
  },
  {
    "objectID": "copilot.html#setting-up-copilot",
    "href": "copilot.html#setting-up-copilot",
    "title": "11  GitHub Copilot",
    "section": "11.2 Setting up Copilot",
    "text": "11.2 Setting up Copilot\nIn order to use Copilot, you’ll need to first sign up for GitHub Education. Instructions can be found here:\nhttps://docs.github.com/en/education/explore-the-benefits-of-teaching-and-learning-with-github-education/github-education-for-students/apply-to-github-education-as-a-student\nYou’ll need to provide your UMN email address and some proof of enrollment. As I recall, UMN student ID cards don’t have enough info on them, so I think I used an “Enrollment Verification” pdf downloaded from MyU (but maybe that was for Spotify…). Anyway, if you are reading this as part of a live workshop, this means you may have to wait a bit for verification before you can actually set up Copilot. Nevertheless, you can return to this site and set things up afterwards.\nOnce you have GitHub Education, you can follow these steps to set up Copilot with GitHub:\nhttps://docs.github.com/en/enterprise-cloud@latest/copilot/managing-copilot/managing-copilot-as-an-individual-subscriber/managing-your-github-copilot-pro-subscription/getting-free-access-to-copilot-pro-as-a-student-teacher-or-maintainer\nBasically, there should be a “Copilot” tab in your account settings where you can activate access.\nWhen you activate, there will be several setting for you to choose. First, there is enabling where Copilot can be used. Personally, I have it set as enabled for GitHub.com, the CLI, and my IDE. Copilot in GitHub.com allows you to chat with it’s chatbot functionality on the website, and you can ask it questions about specific repositories. The CLI is basically your shell or terminal, which you may or may not use. Finally, I believe you need to enable Copilot for your IDE in order to link it to your RStudio, but I am not 100% positive.\nThere are more settings that you’ll want to consider. Perhaps the most important is this: “Suggestions matching public code (duplication detection filter)”. With this enabled, Copilot will make code suggestions that are identical to code snippets from open-source projects housed on public GitHub repositories. However, these projects will have different licenses for use, and if you just use whatever code suggestions you get willy-nilly without proper attribution, you may be violating those licenses. Whenever you do accept one of these suggestions, Copilot will automatically add the license information to a log file, so you can figure out the ways to properly cite these repositories. Personally, I don’t want to deal with that, so I just have this setting disabled. This means that Copilot primarily generates code suggestions based on programming language documentation, tutorials, and your own code (as far as I know).\nThere are also settings to select whether Copilot uses your coding practices for product functionality evaluation and/or training, which you can decide for yourself. Other settings refer to the use of Bing and other LLMs with Copilot, which don’t seem strictly necessary to me for many use cases.\nWith these settings saved, Copilot should be activated for your GitHub account.",
    "crumbs": [
      "git, GitHub, Building Websites, and Copilot",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>GitHub Copilot</span>"
    ]
  },
  {
    "objectID": "copilot.html#copilot-in-rstudio",
    "href": "copilot.html#copilot-in-rstudio",
    "title": "11  GitHub Copilot",
    "section": "11.3 Copilot in RStudio",
    "text": "11.3 Copilot in RStudio\nThe most useful function of Copilot that I have found is using it while I write R code in RStudio.\nInstructions on how to set this up can be found here:\nhttps://docs.posit.co/ide/user/ide/guide/tools/copilot.html\nThe broad strokes are this:\n\nNavigate to Tools &gt; Global Options &gt; Copilot in RStudio\nEnable Copilot\nSign in and verify with your GitHub credentials\n\nAfterwards, Copilot should be connected to your RStudio installation.\nCopilot in RStudio works in two ways. First it will provide tailored code suggestions as you code. Second, it can answer questions within the script editor.\nFor the first application, I have found it incredibly useful, but in order to get good suggestions, documenting your script with descriptive comments is key. First, having a broad goal outlined in ## comments at the top of the script is very helpful. Second, writing ## comments before each section of code describing what you are trying to do and which functions you are using to do it will provide Copilot with the context to generate fairly detailed code for you. As you move through your script in this way, Copilot will pick up on the context and often provide suggestions that match the way you have been coding so far. Whenever Copilot gives you a suggestion, just hit the Tab key to accept it.\nAsking questions in the script editor has not been very useful to me, but your mileage may vary. Use the following format typed into your .R or .qmd file: # q: [question]? and hit enter. Copilot will respond with a # a: answer. Here it had no interest in my small talk:\n# q: what's up copilot?\n# a: I'm just here to help you write code. I'm not a copilot, I'm a code copilot.",
    "crumbs": [
      "git, GitHub, Building Websites, and Copilot",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>GitHub Copilot</span>"
    ]
  },
  {
    "objectID": "copilot.html#copilot-on-github",
    "href": "copilot.html#copilot-on-github",
    "title": "11  GitHub Copilot",
    "section": "11.4 Copilot on GitHub",
    "text": "11.4 Copilot on GitHub\nYou can also use Copilot on the GitHub website for coding questions in a more intuitive way than asking questions within a script.\nOn almost every page on GitHub when you are logged in, there should be an icon near the top right that looks like a little face wearing a old-timey airplane pilot cap. If you click that, it will open a chat subwindow on that page.\nThe nice thing about this functionality is that Copilot can read your repositories, so you don’t have to copy and paste certain code to ask specific questions.\nI used Copilot on GitHub.com to generate a detailed overview of one of my repositories for a README file.\nThere are probably many more ways to use it, but I haven’t played around with it much yet.",
    "crumbs": [
      "git, GitHub, Building Websites, and Copilot",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>GitHub Copilot</span>"
    ]
  },
  {
    "objectID": "account_setup.html",
    "href": "account_setup.html",
    "title": "12  Intro, Packages, and Account Setup",
    "section": "",
    "text": "The goal of this section / workshop is to go over how one can develop a data pipeline with Google Drive where datasheet creation and importing is done entirely in R, without having to manually create Google Sheets or manually download them. We’ll also go over how to manually backup your files.\nFirst, we need to install and call the requisite packages: googledrive and googlesheets4. Overall googledrive is for finding, creating, moving, copying, and deleting files and folders, while googlesheets4 is for reading and writing Google Sheets directly to and from data in your R environment.\nComprehensive info on these packages can be found here: - https://googlesheets4.tidyverse.org/ - https://googledrive.tidyverse.org/\nTo install, you can copy the following code:\n\ninstall.packages(\"googledrive\")\ninstall.packages(\"googlesheets4\")\n\nAnd load them:\n\nlibrary(googledrive)\nlibrary(googlesheets4)\n\n\nAttaching package: 'googlesheets4'\n\n\nThe following objects are masked from 'package:googledrive':\n\n    request_generate, request_make\n\n\nWith these packages loaded, you’ll first need to authorize them with your Google account, such that they can access your drive. You need to authorize both packages separately. Running the functions with no arguments will prompt you to go to your default internet browser to enter your credentials (you may need to make a number selection in the R console).\n\ndrive_auth()\n\ngs4_auth()\n\nYour credentials will be stored in a cache locally on your computer, but not within any given R project folder, so that they can be pulled in any R session. The particulars of this storage process are managed by the “gargle” package, which is a dependency of the google packages. You can find where your credentials are cached with this function:\n\ngargle::gargle_oauth_sitrep()\n\nYou’ll also want to note that when you start running Drive and Sheets functions continually, you will often need to select your authorization or refresh a “stale OAuth token”, which usually just involves selecting a number in the R console.\nIf that doesn’t work, you can just deauthorize and reauthorize the packages, which should fix things (and edit what’s in your gargle cache):\n\ndrive_deauth()\ngs4_deauth()\n\ndrive_auth()\ngs4_auth()\n\nWith this complete, you’ll be able to create and read files in your Google Drive completely through R scripts!",
    "crumbs": [
      "Data Pipelines with Google Drive and Google Sheets",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Intro, Packages, and Account Setup</span>"
    ]
  },
  {
    "objectID": "access_files.html",
    "href": "access_files.html",
    "title": "13  Access Your Files",
    "section": "",
    "text": "Now that you can “talk” between your R session on your local computer and your Google Drive via the internet, we need to go over how to access directories and files on your Drive, or the language with you can do that talking.\nYou are likely familiar with how files are stored on your computer with human-readable filepaths, like so:\n“documents/main_folder/sub_folder/my_document.doc”\nGoogle Drive organizes files and folder similarly, but not the same. Importantly, you can name files and folder on Google Drive with the exact same name, whereas you cannot on your own computer’s operating system. In addition, multiple filepaths can resolve to the same object with how Drive’s are organized. This generally means that using file paths is a bit wonky with these packages.\nThus, to work with Google files programmatically in R, we will want to rely on the “drive_id”s, which are a sequence of letters and numbers unique for each item.\nYou can find the id of a Drive object in its URL - it’s the long sequence at the end. googledrive’s as_id() can isolate it for you, as well as create a special “drive_id” character object for use with googledrive functions.\nI do so here with a folder I made manually on my internet browser called “r_google_demo”:\n\nas_id(\"https://drive.google.com/drive/u/0/folders/1NkwtKkDdxIb7h0LzUBkWD71nG_1eW3f_\")\n\n&lt;drive_id[1]&gt;\n[1] 1NkwtKkDdxIb7h0LzUBkWD71nG_1eW3f_\n\n## I can also save it as an object\nr_google_demo_id &lt;- as_id(\"https://drive.google.com/drive/u/0/folders/1NkwtKkDdxIb7h0LzUBkWD71nG_1eW3f_\") \n\nThere are many things you can do with a drive_id, such as…\n\n## look at its metadata\n## drive_get() also takes full URLs, as it silently uses as_id()\ndrive_get(r_google_demo_id)\n\n! Using an auto-discovered, cached token.\n\n\n  To suppress this message, modify your code or options to clearly consent to\n  the use of a cached token.\n\n\n  See gargle's \"Non-interactive auth\" vignette for more details:\n\n\n  &lt;https://gargle.r-lib.org/articles/non-interactive-auth.html&gt;\n\n\nℹ The googledrive package is using a cached token for 'wojan002@umn.edu'.\n\n\n# A dribble: 1 × 3\n  name          id                                drive_resource   \n  &lt;chr&gt;         &lt;drv_id&gt;                          &lt;list&gt;           \n1 r_google_demo 1NkwtKkDdxIb7h0LzUBkWD71nG_1eW3f_ &lt;named list [36]&gt;\n\n## list what is inside\ndrive_ls(r_google_demo_id)\n\n# A dribble: 2 × 3\n  name           id                                           drive_resource   \n  &lt;chr&gt;          &lt;drv_id&gt;                                     &lt;list&gt;           \n1 my_sheets      1F7qR0tUUqZ0T5BfoF8rW2lEvrS8a3A1d            &lt;named list [36]&gt;\n2 sheet_template 1blxzA8Dg_KOsT7va8LzP_M4rvDqdCcpVuSjHklbT-7E &lt;named list [37]&gt;\n\n\nBoth of these functions return “dribbles” which are a type of data frame (more precisely, a tidyverse tibble) that contain the name, id, and metadata (in list form) of Drive objects. That metadata may be useful for more advanced processes.\nIt should be noted that drive_ls() can be used without an argument to list out a full drive, but in the case of UMN accounts, this also includes everything that is shared with you, so the function will take a tremendously long time to return all those objects. This also applies to the drive_find() function, which seeks objects based on a character string; it will search everything you have access to.\nIf you want to drive_find() within specific folder of yours, you’ll need to learn query strings for the Google API here (I have not!):\nhttps://developers.google.com/workspace/drive/api/guides/search-files\nHowever, we can still import certain files into R based on criteria that we define using the drive_ls() function, as we will see later.\nBut first we will see how to create files, particularly sheets for data entry.",
    "crumbs": [
      "Data Pipelines with Google Drive and Google Sheets",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Access Your Files</span>"
    ]
  },
  {
    "objectID": "create_sheets.html",
    "href": "create_sheets.html",
    "title": "14  Create New Files and Folders",
    "section": "",
    "text": "So we can look at the ids and metadata of our files, but that’s not very fun.\nLet’s create some files!\nSometimes, when you have a research project, you want to create several datasheets with the same template for data entry. On paper, you just print out a bunch of copies. But if you are entering your data electronically with Google Drive, you might want to make several files, for the sake of organization and navigation within a given file. Let’s say we are going to do just that!\nFirst, let’s create a folder:\n\n## name is required\n# you can also specify a path to a folder as an id, one-row dribble, or character path (I use \"~/\" to specify home directory)\n# you can also tell whether to overwrite (NA means create even if it duplicates)\ndrive_mkdir(name = \"my_new_folder\", path = \"~/\", overwrite = TRUE)\n\n! Using an auto-discovered, cached token.\n\n\n  To suppress this message, modify your code or options to clearly consent to\n  the use of a cached token.\n\n\n  See gargle's \"Non-interactive auth\" vignette for more details:\n\n\n  &lt;https://gargle.r-lib.org/articles/non-interactive-auth.html&gt;\n\n\nℹ The googledrive package is using a cached token for 'wojan002@umn.edu'.\n\n\nCreated Drive file:\n\n\n• 'my_new_folder' &lt;id: 1IKCX4jvljOteHvZR-5Rdmfp9dbiFzb2x&gt;\n\n\nWith MIME type:\n\n\n• 'application/vnd.google-apps.folder'\n\n## you can also save its ID while creating\n## here I am overwriting what I created, but I need to specify the path\n## to my home directory for the dribble conversion\nmy_new_folder_id &lt;- drive_mkdir(name = \"my_new_folder\", path = \"~/\", overwrite = TRUE)\n\nFile trashed:\n\n\n• 'my_new_folder' &lt;id: 1IKCX4jvljOteHvZR-5Rdmfp9dbiFzb2x&gt;\n\n\nCreated Drive file:\n\n\n• 'my_new_folder' &lt;id: 1cwaFg-OSi9Xw5w9tHh3xbmiOseDAhtfT&gt;\n\n\nWith MIME type:\n\n\n• 'application/vnd.google-apps.folder'\n\n## this way we can easily refer to it in future code\n\nThere are more arguments you can pass to the Google Drive API, e.g. setting permissions, but that gets more complicated (and I don’t know how!).\nYou should see that folder in your home directory on your Drive now.\nNow we can fill it with new files!\n\n## make a folder inside our new folder\nsubfolder_id &lt;- drive_mkdir(name = \"subfolder\", path = my_new_folder_id)\n\nCreated Drive file:\n\n\n• 'subfolder' &lt;id: 1YAf44HNrAVPc7eHSmcD2pVAx1LPyrndy&gt;\n\n\nWith MIME type:\n\n\n• 'application/vnd.google-apps.folder'\n\n## make a blank file inside our new folder\nsheet_template_id &lt;- drive_create(name = \"sheet_template\", path = my_new_folder_id,\n                               type = \"spreadsheet\")\n\nCreated Drive file:\n\n\n• 'sheet_template' &lt;id: 1Oxp_zuoKdIvbf8Lj_Kn0904tAkWuVvn9FmrkedAJvfw&gt;\n\n\nWith MIME type:\n\n\n• 'application/vnd.google-apps.spreadsheet'\n\n# other types include \"documents\" and \"slides\"\n\n## upload a file to your new folder\n## (file is included in this github repo)\nupload_id &lt;- drive_upload(media = \"template.csv\", path = my_new_folder_id, name = \"sheet_upload\", \n                          type = \"spreadsheet\")\n\nLocal file:\n\n\n• 'template.csv'\n\n\nUploaded into Drive file:\n\n\n• 'sheet_upload' &lt;id: 1tWzvKCerQtARK6-zFQNsGq3a1_mPVhxU1brJ7dsdfyI&gt;\n\n\nWith MIME type:\n\n\n• 'application/vnd.google-apps.spreadsheet'\n\n\n“sheet_template” is a blank sheet, while “sheet_upload” is filled with what is written in the “template.csv”. We can look at that here:\n\n## read\ntemplate &lt;- read.csv(\"template.csv\")\n\n## display\ntemplate\n\n   date site plot point temp value\n1    NA   NA    A     1   NA    NA\n2    NA   NA    A     2   NA    NA\n3    NA   NA    A     3   NA    NA\n4    NA   NA    A     4   NA    NA\n5    NA   NA    B     1   NA    NA\n6    NA   NA    B     2   NA    NA\n7    NA   NA    B     3   NA    NA\n8    NA   NA    B     4   NA    NA\n9    NA   NA    C     1   NA    NA\n10   NA   NA    C     2   NA    NA\n11   NA   NA    C     3   NA    NA\n12   NA   NA    C     4   NA    NA\n\n\nThis is a generic example of some date you might want to record for several site and dates We could write this directly to the blank sheet we created, but assuming we didn’t have this csv, we can also create the same template in R:\n\n## create template as a data frame\nmanual_template &lt;- data.frame(\n  date = NA,\n  site = NA,\n  plot = rep(c(\"A\",\"B\",\"C\"), each = 4),\n  point = rep(1:4, 3),\n  temp = NA,\n  value = NA\n)\n\n## now we can write that data frame to the empty sheet we created above\n## note: up to this point the functions have been from googledrive, \n## writing and reading sheets is done with googlesheets4\n\n## use sheet_write to write to sheets (you can specify tab with the \"sheet\" argument by name or number) \nsheet_write(data = manual_template, ss = sheet_template_id, sheet = 1)\n\n! Using an auto-discovered, cached token.\n\n\n  To suppress this message, modify your code or options to clearly consent to\n  the use of a cached token.\n\n\n  See gargle's \"Non-interactive auth\" vignette for more details:\n\n\n  &lt;https://gargle.r-lib.org/articles/non-interactive-auth.html&gt;\n\n\nℹ The googlesheets4 package is using a cached token for 'wojan002@umn.edu'.\n\n\n✔ Writing to \"sheet_template\".\n\n\n✔ Writing to sheet 'Sheet1'.\n\n\nNow the two sheets in your folder should match, but the one you wrote to with sheet_write doesn’t have any cells around the data frame itself.\nThe next step would be to create a sheet for each of several sites. There are several ways to do this. You could copy your template with googledrive::drive_cp() and then write a new data frame to each new copy with googlesheets4::sheet_write as above. You could also use googlesheet4’s built-in sheet creation function, gs4_create, but then you’ll have to move them with googledrive::drive_mv. Either way it’s a two-step process; here we will try out those new functions:\n\n## first create a folder to hold the sheets\nsite_sheets_id &lt;- drive_mkdir(name = \"site_sheets\", path = my_new_folder_id)\n\nCreated Drive file:\n\n\n• 'site_sheets' &lt;id: 1gV5c5iVHFr5bRdaqYEYFjE3Xib7EyX5r&gt;\n\n\nWith MIME type:\n\n\n• 'application/vnd.google-apps.folder'\n\n## let's make some arbitrary sites\nsites &lt;- c(\"S1\", \"S2\", \"S3\", \"S4\", \"S5\")\n\n## create an empty list to write sheet ids\nnew_sheets &lt;- list()\n\n## loop over each site\nfor (i in 1:length(sites)){\n  df &lt;- manual_template # grab template\n  df$site &lt;- sites[i] # set site to current label\n  sheet_name &lt;- paste0(sites[i],\"_data\")\n  ## create new sheet and save id to vector\n  temp_id &lt;- gs4_create(name = sheet_name, sheets = df)\n  new_sheets &lt;- c(new_sheets, temp_id)\n  ## move sheet to folder\n  drive_mv(file = as_id(new_sheets[[i]]), path = site_sheets_id)\n}\n\n✔ Creating new Sheet: \"S1_data\".\n\n\nOriginal file:\n\n\n• 'S1_data' &lt;id: 1lLGKSCulRUrBHCVoM5bn0_t9AyIP-DOegMOsxbvs6Po&gt;\n\n\nHas been moved:\n\n\n• 'site_sheets/S1_data' &lt;id: 1lLGKSCulRUrBHCVoM5bn0_t9AyIP-DOegMOsxbvs6Po&gt;\n\n\n✔ Creating new Sheet: \"S2_data\".\n\n\nOriginal file:\n\n\n• 'S2_data' &lt;id: 1OFqpJwD5y5ZUP4BZsXw-EirA5mD0u6rzXkT43JIIcQ4&gt;\n\n\nHas been moved:\n\n\n• 'site_sheets/S2_data' &lt;id: 1OFqpJwD5y5ZUP4BZsXw-EirA5mD0u6rzXkT43JIIcQ4&gt;\n\n\n✔ Creating new Sheet: \"S3_data\".\n\n\nOriginal file:\n\n\n• 'S3_data' &lt;id: 1wF0CoBt8QF0TuTTV0tU5h45y0HCO9BUzi3IJoYER5f4&gt;\n\n\nHas been moved:\n\n\n• 'site_sheets/S3_data' &lt;id: 1wF0CoBt8QF0TuTTV0tU5h45y0HCO9BUzi3IJoYER5f4&gt;\n\n\n✔ Creating new Sheet: \"S4_data\".\n\n\nOriginal file:\n\n\n• 'S4_data' &lt;id: 1MJ9isVIMKB3TpD0r4oUgg8XJsoQrevkh6p94YyZTpgY&gt;\n\n\nHas been moved:\n\n\n• 'site_sheets/S4_data' &lt;id: 1MJ9isVIMKB3TpD0r4oUgg8XJsoQrevkh6p94YyZTpgY&gt;\n\n\n✔ Creating new Sheet: \"S5_data\".\n\n\nOriginal file:\n\n\n• 'S5_data' &lt;id: 18s1GMtNJD0gtfttoXHY6dlFRrNAZ3VoAQwP8g0arcf4&gt;\n\n\nHas been moved:\n\n\n• 'site_sheets/S5_data' &lt;id: 18s1GMtNJD0gtfttoXHY6dlFRrNAZ3VoAQwP8g0arcf4&gt;\n\n\nHooray! Now you have a set of Google Sheets following that template! Of course, manually doing this would have been faster than writing this script, but that comparison quickly becomes favorable for coding when the number of datasheets grows or the number of time you need to create a new set of datasheets.\nNote: for many of these processes I might recommend writing functions and using functionals like the purrr::map family or base R’s apply family, but loops work fine too.\nIn any case, the next step is to enter data, I suppose!",
    "crumbs": [
      "Data Pipelines with Google Drive and Google Sheets",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Create New Files and Folders</span>"
    ]
  },
  {
    "objectID": "backup_data.html",
    "href": "backup_data.html",
    "title": "15  Backup Your Data",
    "section": "",
    "text": "So let’s say you’ve entered some data.\nThe files are there on Google’s cloud service, to be accessed from any local device. You can also download them manually. Of course, you may be in the middle of data collection, so the files in your folders are subject to change.\nIn the case of a blank spreadsheet you created based off of a template, Google will track changes in the version history, but Google is not clear on how long it will keep those changes accessible, or when/if nearby changes are “collapsed” into versions that summarize your versions. This is no good for being able to look back, or general scientific data management principles right?\nWell, you can set up a script to download a snapshot of your data to your computer whenever you run it!\nThis actually will require some functions to manipulate files on your own computer, so let’s go over those first:\n\n## First you want to save a directory where you want to store your backups\nupper_dir &lt;- \"~/Documents/UMN/data_backups/research_project_1\"\n## and then set your R session to that directory\nsetwd(upper_dir)\n\nNext, we will create a folder to hold today’s backups:\n\n## save current date\ncur_date &lt;- Sys.Date()\n\n## create a name for the folder with the date\ndir_name &lt;- paste0(\"project1_data_backup_\", cur_date)\n\n## create a folder with that name in the working directory\ndir.create(dir_name)\n\n## now enter backup directory\nsetwd(paste0(upper_dir, \"/\", dir_name))\n\nNow that we have our file directories set up, we can download our files. But first we need to identify them:\n\n## of course we need to know where to find our files\ndata_folder &lt;- drive_get(\"[your folder URL or id here]\")\n\n## and then we want the ids of the data within (spreadsheets)\n## recursive = TRUE returns data in subfolders\ndata_ids &lt;- drive_ls(data_folder, type = \"spreadsheet\", recursive = TRUE)\n\nThe data_ids object will be a dribble, with and id column storing the drive ids. We can call it sequentially to download each file to our current working directory (which is our newly created subfolder).\n\n## download in a loop\nfor (i in data_ids$id) {\n  drive_download(file = as_id(i), type = \"csv\")\n}\n\n## you could also download with walk from purrr\npurrr::walk(data_ids$id, ~ drive_download(file = as_id(.x), type = \"csv\"))\n\nFinally, since this is a backup, we can compress the folder to save storage space:\n\n## move up a directory\nsetwd(upper_dir)\n\n## zip backup folder\nzip(zipfile = dir_name, files = dir_name)\n\n## optionally remove the unzipped folder\nunlink(dir_name, recursive = TRUE)\n\nYou can do this as often as you want; I do it at the end of every data collection day. But if you do it more than daily, you’ll need to create a more detailed folder name than just the date - you could add a full timestamp with Sys.time().",
    "crumbs": [
      "Data Pipelines with Google Drive and Google Sheets",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Backup Your Data</span>"
    ]
  },
  {
    "objectID": "read_sheets.html",
    "href": "read_sheets.html",
    "title": "16  Read Your Data",
    "section": "",
    "text": "Now for possibly the most useful part - reading Google Sheets directly into R. For some this may be the only relevant part if you prefer to manually work with your sheets on Google Drive.\nReally, the only function you need to learn here is googlesheets4::read_sheet(), and it functions very similarly to base R’s read.csv(), and read_csv() from the tidyverse. As such, it also has arguments for setting column types (or guessing them), how to read missing values, skipping rows, etc.\nAnyway, now that you know all about drive ids and such, it’ll be easier to use.\nSimilar to backing up your data, you’ll need to get the drive id of where your data is stored. You can consider saving the URL/id to a file in your project directory (which you then read into your environment) if you don’t want to hard code it into your script, but the only difference that makes is that it is then “secret” if you upload your script to github.\nAnyway, the general steps are:\n\n## save the id as an id object, simii\ndata_folder &lt;- drive_get(\"[your data folder URL or id here]\") \n\n## now get your files\ndata_ids &lt;- drive_ls(data_folder, type = \"spreadsheet\", recursive = TRUE)\n\nNow instead of downloading these files to you computer, we’re going to read them into your environment. Again you can do it with a functional like purrr::map(), or by looping. Here is a simple looping approach:\n\n## create empty data.frame for data\ndf &lt;- data.frame()\n\n## run through each data id\n## note: this only works if the data have the same columns!!\nfor(i in data_ids$id) {\n  new_df &lt;- read_sheet(ss = i)\n  df &lt;- rbind(df, new_df)\n}\n\nNow, your data is in R for you to manipulate as you wish!\nObviously this is a very simple case, and your data may be a lot more complicated. With the functions described in this chapter overall, you should be able to modify things to your specifications. However, in some complex cases you may want to explore reading certain data sheets into a “list column” in a tidyverse tibble, that you can unnest and renest as needed. I personally do this, but it is likely unnecessary for many cases.\nAfter you have processed your data, you could even upload it to your Google Drive using the methods in the “Create New Files and Folders” section! =)",
    "crumbs": [
      "Data Pipelines with Google Drive and Google Sheets",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Read Your Data</span>"
    ]
  }
]