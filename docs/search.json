[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "UMN EEB Quant/Comp Repo",
    "section": "",
    "text": "Hello!\nThis site/book will serve as a repository for resources related to computational and quantitative workshops held for the University of Minnesota’s Ecology, Evolution, and Behavior Graduate Program through its “Friday Noon Seminar” series.\nIt is a “living document,” and thus will be subject to change and be updated over time."
  },
  {
    "objectID": "intro_iteration.html",
    "href": "intro_iteration.html",
    "title": "1  Intro to Iteration",
    "section": "",
    "text": "This workshop will be focused on iteration, or performing the same code numerous times, potentially on some range of values, in R. It assumes that you know most of the basics of R programming.\nR has various ways to iterate, including looping, using functions/functionals, and vectorization. We will go over each to some extent, with examples included. A general guideline for iterating is that if you are copying and pasting code multiple times, you may be better served with a loop or a function. We will cover the following:\n\nLoops\n\nTypes of loops: for, while, and repeat\nWhen to use which types of loops\nPotential downsides of using loops\nWhen use a loop is still necessary anyway\n\nFunctions and Functionals\n\nHow to write functions\nBenefits of functions\nHow to iterate functions with the purr package\nHow to iterate even faster with parallel computing\n\nVectorization\n\nBenefits of vectorization\nLimitations"
  },
  {
    "objectID": "loop_types.html",
    "href": "loop_types.html",
    "title": "2  Types of Loops",
    "section": "",
    "text": "The first method of iteration that most people learn is looping, or using flow control to rerun a block of code some number of times, or over a range of values. Many of you will be familiar with this, so we will just review it a bit.\nR has different type of loops, including for, while, and repeat.\n\n2.0.1 for loops\nfor loops are the most commonly used loop, as they are versatile to many contexts. They generally follow the form:\n\nfor (indexing_variable in range_of_values) {\n  some_function(some_argument = indexing_variable)\n}\n\nIn the first line, an indexing variable is created to keep track of iterations, and it iterates through the range of values provided.\nThen, some code is provided within brackets to be performed for each value in the range of values. Usually, the indexing variable will be referenced somehow in this code, but it doesn’t need to be if you are just doing the same exact thing several times.\nHere is a really silly working example:\n\n## square the numbers 1 through 5\nfor (i in 1:5) {\n  print(i^2)\n}\n\n[1] 1\n[1] 4\n[1] 9\n[1] 16\n[1] 25\n\n## of course you could just do this instead and get a more useable vector\n(1:5)^2\n\n[1]  1  4  9 16 25\n\n\nNow let’s look at a more interesting example. Let’s say you are interested in the effect of some independent variable on multiple dependent variables. First let’s simulate some fake data of greenhouse plant growth under two watering conditions:\n\n## create a data frame with 60 total plants and\n## -two treatment levels, control and drought\n## -plant heights, masses, and seed masses sampling from a normal distribution\nplant_data &lt;- data.frame(treatment = rep(c(\"control\",\"drought\"), each = 30),\n                         height_cm = rnorm(n = 60, mean = rep(c(12,8), each = 30), sd = 2),\n                         dry_biomass_g = rnorm(60, mean = rep(c(50, 40), each = 30), sd = 6),\n                         seed_mass_mg = rnorm(60, mean = rep(c(30, 20), each = 30), sd = 4))\n\nNow we are probably interested in how the watering influences these variables (i.e., with a t-test), but we don’t want to write the code, and then copy and paste it twice. Here’s how we use a for loop:\n\n## create a vector of dependent variables to loop over\ndep_vars &lt;- c(\"height_cm\", \"dry_biomass_g\", \"seed_mass_mg\")\n\n## pre allocate a list to store results\nresult_list &lt;- vector(mode = \"list\", length = length(dep_vars))\n\n## let's name the list as well\nnames(result_list) &lt;- dep_vars\n\n## set up a loop to iterate through variables\nfor (i in dep_vars) {\n  ## store t test results in our list\n  result_list[[i]] &lt;- t.test(plant_data[,i] ~ plant_data[,\"treatment\"])\n}\n\n## check out the results!\nresult_list\n\n$height_cm\n\n    Welch Two Sample t-test\n\ndata:  plant_data[, i] by plant_data[, \"treatment\"]\nt = 6.3205, df = 53.614, p-value = 5.339e-08\nalternative hypothesis: true difference in means between group control and group drought is not equal to 0\n95 percent confidence interval:\n 2.341790 4.518115\nsample estimates:\nmean in group control mean in group drought \n            11.786786              8.356833 \n\n\n$dry_biomass_g\n\n    Welch Two Sample t-test\n\ndata:  plant_data[, i] by plant_data[, \"treatment\"]\nt = 7.0993, df = 54.422, p-value = 2.733e-09\nalternative hypothesis: true difference in means between group control and group drought is not equal to 0\n95 percent confidence interval:\n  6.755264 12.070890\nsample estimates:\nmean in group control mean in group drought \n             50.83554              41.42246 \n\n\n$seed_mass_mg\n\n    Welch Two Sample t-test\n\ndata:  plant_data[, i] by plant_data[, \"treatment\"]\nt = 11.788, df = 57.212, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group control and group drought is not equal to 0\n95 percent confidence interval:\n  9.772532 13.771906\nsample estimates:\nmean in group control mean in group drought \n             30.85710              19.08488 \n\n\nWhen you are writing a for loop (especially ones more complex than the above), it can be helpful to first develop the code within the loop to more easily debug it. For example:\n\n## set the iterator variable to one of the values to be looped through\ni &lt;- dep_vars[1]\n\n## then try coding what you want to do repeatedly\ntest_result &lt;- t.test(plant_data[,i] ~ plant_data[,\"treatment\"])\ntest_result\n\n\n    Welch Two Sample t-test\n\ndata:  plant_data[, i] by plant_data[, \"treatment\"]\nt = 6.3205, df = 53.614, p-value = 5.339e-08\nalternative hypothesis: true difference in means between group control and group drought is not equal to 0\n95 percent confidence interval:\n 2.341790 4.518115\nsample estimates:\nmean in group control mean in group drought \n            11.786786              8.356833 \n\n\nThis can be helpful because R, like most programming languages, is very particular about syntax. If you had tried to use the $ operator to select columns, you would have gotten an error:\n\n## this doesn't work because i is a character value in quotes, which is incompatible with $\nt.test(plat_data$i ~ plant_data$treatment)\n\nThere are some “common pitfalls” to writing for loops, which I hope I have avoided here. You can read about them in more detail here:\nhttps://adv-r.hadley.nz/control-flow.html#common-pitfalls\n\n\n2.0.2 while loops\nwhile loops are a bit less common, but can be useful in certain contexts (mostly simulation). They follow this form:\n\nwhile (some_condition == TRUE) {\n  some_function()\n}\n\nThe first line provides a conditional statement to be evaluated at each iteration, if it is met the loop will continue to run, if it is not met the loop will close.\nThere are two uses for while loop that I have found. The first is when there is some degree of randomness in how many iterations need to be run. Let’s say for example you want to simulate a population of organisms that aggregate in groups, but you want to allow the group sizes to vary while the global population size remains the about the same. In this case, you could use a while loop:\n\n## first let's set the population size to 0\nN &lt;- 0\n\n## and create an empty vector for group size\ngroups &lt;- NULL\n\n## and a counter variable\ncounter &lt;- 1\n\n## now let's start the while loop\nwhile (N &lt; 100) {\n  ## randomly generate a group size as a pull from a poisson distribution w/ a mean of 5\n  groups[counter] &lt;- rpois(n = 1, lambda = 5)\n  ## calculate total pop size\n  N &lt;- sum(groups)\n  ## increase counter\n  counter &lt;- counter + 1\n}\n\nIf you run that code multiple times, you’ll see that you will end up with different numbers of groups with different numbers of members. This could be useful for simulation models or parametric bootstrapping. However, you may also notice that the total population size here isn’t exactly constant. To keep it constant, you could do something like this:\n\n## first let's set the population size to 0\nN &lt;- 0\n\n## and create an empty vector for group size\ngroups &lt;- NULL\n\n## and a counter variable\ncounter &lt;- 1\n\n## now let's start the while loop\nwhile (N &lt; 100) {\n  ## calculate remaining population to fill\n  to_fill &lt;- 100 - sum(groups)\n  ## randomly generate a group size as a pull from a poisson distribution w/ a mean of 5\n  ## but if it is larger than the remaining population to fill, just fill it up exactly\n  groups[counter] &lt;- min(rpois(n = 1, lambda = 5), to_fill)\n  ## calculate total pop size\n  N &lt;- sum(groups)\n  ## increase counter\n  counter &lt;- counter + 1\n}\n\nNifty!\nThe other use of a while loop that I have found is for a brute force algorithm. Basically, if you have do something complex but don’t have the time or mental energy to figure out the precise algorithm to do it, you can do it the “stupid” way. This is basically like trying every combination on a lock until it opens. Computer scientists frown on these methods for being highly inefficient, but we are computer scientists. For ecology/evolution/behavior contexts, you might use a brute force while loops to try random combinations of data or sample sets of observations with many characteristics until you find a combination/set that meets highly specific criteria that you are looking for (e.g., subsampling a large dataset such that you sample randomly but also cover a wide range of treatment levels, sampling dates, etc.).\n\n\n2.0.3 repeat loops\nrepeat loops are a very basic sort of loop that simply do something over an over again until a condition is met, then they close. Here’s the form:\n\nrepeat {\n  some_function()\n  if (some_condition == TRUE) break\n}\n\nTo me they kind of seem like a while loop formatted differently. I suppose you could add multiple “break” points for different end conditions, but I believe you can add “break” commands to any type of loop.\nLet me know if you know of cases where repeat loops are effective!"
  },
  {
    "objectID": "when_loops.html",
    "href": "when_loops.html",
    "title": "3  When to Loop?",
    "section": "",
    "text": "Now you may have often heard that you should avoid using for loops because they are slow. This isn’t strictly true; it depends how you write them. It has to do with how R uses your computer’s working memory, but the details are probably not worth getting into. Generally if you avoid the “common pitfalls” linked in the last section, you should be writing loops that are plenty fast. Also, in my personal opinion, I’m not sure how important speed is for most of our work - since we’re not developing software or data pipelines for business purposes, we are more interested in the end result and less interested in how long it took our program to get there. All this to say, don’t worry about the for loops you use being inefficient. A good guideline might be: do what you need to do now to get your results, and maybe do it a little better next time.\nHowever, there are other reasons not to use for loops that I think are more compelling, and we’ll talk about them when we talk about functions. But sometimes you just have to use loops. How can you know?\nBasically -\nYou need to use a loop when the process of one iteration depends on the outcome of previous iteration/s.\nThe while loop we used in the last section is technically an example of a case where a loop is necessary, but let’s look at another clearer ecological example: discrete population growth.\nLet’s use one common formulation of discrete logistic growth:\n\\[\nN_{t+1} = N_t *e^{r(\\frac{K-N_t}{K})}\n\\]\nWhere N is population size, r is growth rate, and K is carrying capacity.\nAs you can see, that pesky Nt is involved in the calculation of Nt+1, or in other words, the process of calculation for one iteration/timestep depends on the outcome of the previous iteration/timestep. Thus we need to use a loop:\n\n## set growth rate, r, and carrying capacity K\nr &lt;- 1\nK &lt;- 100\n\n## set number of timesteps, t, and preallocate population size vector, N\nt &lt;- 20\nN &lt;- vector(mode = \"numeric\", length = t)\nN[1] &lt;- 1\n\n## loop through timesteps and calculate population size\n## note: we are considering t = 1 as initial pop size\nfor (i in 1:(t - 1)) {\n  N[i+1]  = N[i] * exp(r * ((K-N[i])/K))\n}\n\n## plot the output                                 \nplot(1:t, N, type = \"o\", xlab = \"t\")\n\n\n\n\nThis relatively simple loop is what powers this web app:\nhttps://cwojan.shinyapps.io/discrete_logistic_growth/\nCool!"
  },
  {
    "objectID": "functions.html",
    "href": "functions.html",
    "title": "4  Functions",
    "section": "",
    "text": "So we just went over the contexts when you need to use loops, but what else can you do when looping isn’t necessary (i.e., the process of one iteration does not depend on previous iterations)?\nYou can write your own functions and use functionals to iterate them! We’ll talk about functionals in the next section, but for now let’s go over how to write functions and why.\n\n4.0.1 How to Write Functions\nYou are all familiar with functions in general, we’ve been using them all throughout this workshop! However, the ones we’ve been using are premade for us. Now, we will write our own.\nA function is made up of a couple of things: a name, one or more arguments, and body of code. You can make one with the following form:\n\nnew_function &lt; function(some_argument, some_default = \"default\"){\n  output &lt;- what_the_function_does(some_argument, default)\n  return(output)\n}\n\nWe start by providing our function name, “new_function”, and we assign the output of the “function” function to that name as an object. (That sentence had a alot of “functions” in it…). Within the parentheses of the “function” function we can provide what arguments we want our new_function to have. We can set a default value for an argument by setting an argument = to some value or data structure. Finally, we provide what the function does in the brackets after the end parentheses. We can set what new_function’s output will be with the return() statement.\nNow let’s do a working example, using our fake plant data that we used with a for loop earlier. Here’s the code to generate it again:\n\n## create a data frame with 60 total plants and\n## -two treatment levels, control and drought\n## -plant heights, masses, and seed masses sampling from a normal distribution\nplant_data &lt;- data.frame(treatment = rep(c(\"control\",\"drought\"), each = 30),\n                         height_cm = rnorm(n = 60, mean = rep(c(12,8), each = 30), sd = 2),\n                         dry_biomass_g = rnorm(60, mean = rep(c(50, 40), each = 30), sd = 6),\n                         seed_mass_mg = rnorm(60, mean = rep(c(30, 20), each = 30), sd = 4))\n\nNow let’s create a function to do a t-test for a given dependent variable. But this time instead of creating a list of statistical output, let’s make it output just a few numbers of interest: the effect size (mean difference in this case), the 95% confidence interval, and the p value.\n(this can be done with functions in the broom package, but it is a simple task that’s good for demonstration purposes).\nInstead of jumping right into the function, I’m going to figure out how to pull out those values, and then make the function (for easier debugging)\n\n## let's imagine a function that takes three arguments: \n## dat for the data frame, treatment for the categorical column,\n## and measurement for the dependent variable of interest\n## let's set them to play with:\ndat &lt;- plant_data\ntreatment &lt;- \"treatment\"\nmeasurement &lt;- \"height_cm\"\n\n## now let's put those into a t_test\ntest_result &lt;- t.test(dat[,measurement] ~ dat[,treatment])\n\n## we can pull out values with $, for example\ntest_result$p.value\n\n[1] 2.355752e-08\n\n## so make it a dataframe\nclean_result &lt;- data.frame(mean_diff = diff(test_result$estimate),\n                           ci_lwr = test_result$conf.int[1],\n                           ci_upr = test_result$conf.int[2],\n                           p_val = test_result$p.value)\nclean_result\n\n                      mean_diff   ci_lwr   ci_upr        p_val\nmean in group drought -3.508869 2.424642 4.593095 2.355752e-08\n\n\nThat looks like what we want! There is a inaccurate row name, but we can ignore that because it won’t really affect anything. Now let’s write it as a function!\n\n## let's name our function quick_t_test and give it our three arguments\nquick_t_test &lt;- function(dat, treatment, measurement){\n  ## do t test\n  test_result &lt;- t.test(dat[,measurement] ~ dat[,treatment])\n  ## pull out summary\n  clean_result &lt;- data.frame(mean_diff = diff(test_result$estimate),\n                           ci_lwr = test_result$conf.int[1],\n                           ci_upr = test_result$conf.int[2],\n                           p_val = test_result$p.value)\n  ## return the clean_result as output from the function\n  return(clean_result)\n}\n\nNote: the “return” command isn’t strictly necessary here, because custom R functions will default to returning the last object created. However, I like to be explicit, especially when you create multiple object in a function.\nNow let’s test out our function!\n\n## use quick t test on our fake data\nquick_t_test(dat = plant_data, treatment = \"treatment\", measurement = \"height_cm\")\n\n                      mean_diff   ci_lwr   ci_upr        p_val\nmean in group drought -3.508869 2.424642 4.593095 2.355752e-08\n\n## try another variable\nquick_t_test(dat = plant_data, treatment = \"treatment\", measurement = \"dry_biomass_g\")\n\n                      mean_diff   ci_lwr   ci_upr        p_val\nmean in group drought -9.195879 6.309072 12.08269 3.466451e-08\n\n\nIt works! In the next section, we will apply this function iteratively with functionals, and the true power of functions will be apparent.\nOne more thing to note about functions is the distinction between local and global variables. Within the body of the function, any variable you create is local to the function, so only exists while the function is running. After it completes, you will only have access to whatever you’ve returned. Global variable are what exist outside of the function in your environment. You can refer to them inside a function, but it makes the function less versatile.\n\n\n4.0.2 Benefits of Writing Functions\nFunctions can be an efficient way to write your code for a variety of reasons. As mentioned before, some people prefer iterating functions with functionals for processing speed reasons, but I don’t think that is as important for us, and in many cases there may not be a speed difference. Instead, I think writing functions is helpful because:\n\nThey can be easier to read. Looking back at code with a complicated nested for loop can be tough to parse, but code organized into functions can be easier to get a handle on.\nThey can be faster to write. I find myself getting things done quicker when I use functions - loops seemed to take longer to write and troubleshoot.\nThey can be transportable. Once you’ve written a generic function, you can copy and paste it into any old script where it would be useful, while it would be harder to do that with a loop.\nThey can make organizing large projects easier. Often people will create one script with all the functions for a certain analysis, and then other scripts where the analysis is run and output produced. This can be easier to keep track of and lead to shorter scripts to scroll through.\nThey can make your code modular. You can make your script a system of components that work together, functions can call other functions, and bugs are usually isolated to individual components."
  },
  {
    "objectID": "purrr.html",
    "href": "purrr.html",
    "title": "5  Functionals with purrr",
    "section": "",
    "text": "Now that we’ve written a function, let’s use it efficiently with functionals. Functionals are functions that take other functions as one of their arguments, and then can apply that function a number of times or to a range of values (much like a loop!). Base R has the “apply” family of functionals, including lapply and sapply, but I’ve found those difficult to learn because they have inconsistent syntax and behavior. Instead, we will use the “map” functionals from the “purrr” package. It’s part of the tidyverse, so you likely already have it installed. If not, use this code:\n\ninstall.packages(\"purrr\")\n\nNow, we can load the package, and make sure we have our fake plant data and quick_t_test function in our environment.\n\nlibrary(purrr)\n\nplant_data &lt;- data.frame(treatment = rep(c(\"control\",\"drought\"), each = 30),\n                         height_cm = rnorm(n = 60, mean = rep(c(12,8), each = 30), sd = 2),\n                         dry_biomass_g = rnorm(60, mean = rep(c(50, 40), each = 30), sd = 6),\n                         seed_mass_mg = rnorm(60, mean = rep(c(30, 20), each = 30), sd = 4))\n\nquick_t_test &lt;- function(dat, treatment, measurement){\n  ## do t test\n  test_result &lt;- t.test(dat[,measurement] ~ dat[,treatment])\n  ## pull out summary\n  clean_result &lt;- data.frame(mean_diff = diff(test_result$estimate),\n                           ci_lwr = test_result$conf.int[1],\n                           ci_upr = test_result$conf.int[2],\n                           p_val = test_result$p.value)\n  ## return the clean_result as output from the function\n  return(clean_result)\n}\n\n\n5.0.1 The Basic map Functional\nNow let’s use the map functional to iterate our quick_t_test function over each of our dependent variables. We simply provide it what we want to iterate over and then we provide the function we want it to do as arguments. Let’s go over a simple example first, making vectors of randomly generated numbers of different lengths, 1 through 5.\n\nmap_results &lt;- map(.x = 1:5, ## iterate over .x\n                   .f = rnorm) ## and do .f\n\n## we get a list of vectors\nmap_results\n\n[[1]]\n[1] -0.3792941\n\n[[2]]\n[1] -0.05003484 -0.34604296\n\n[[3]]\n[1]  1.4456541 -0.8184218  0.2982851\n\n[[4]]\n[1]  0.2120991 -0.9364113 -0.7795585 -0.2158808\n\n[[5]]\n[1]  0.9620472  0.7956544 -0.4623511  0.3488813 -1.3421138\n\n\nOne thing that is implicitly going on here is that 1:5 is being plugged into the first argument of rnorm by default, which is the number of observations to generate. The mean and sd default to 0 and 1 respectively (as indicated in the help doc for rnorm). However, our function has three arguments with no defaults, so we will need to supply those arguments and values in the map functional to do a quick t test for each of three variables:\n\n## quick t test each dependent variable\nttest_results &lt;- map(.x = c(\"height_cm\", \"dry_biomass_g\", \"seed_mass_mg\"),\n                     .f = quick_t_test,\n                     dat = plant_data, treatment = \"treatment\")\n\n## show results\nttest_results\n\n[[1]]\n                      mean_diff   ci_lwr   ci_upr        p_val\nmean in group drought -4.245301 3.059107 5.431496 1.683137e-09\n\n[[2]]\n                      mean_diff   ci_lwr   ci_upr        p_val\nmean in group drought -9.071756 5.592005 12.55151 2.664831e-06\n\n[[3]]\n                      mean_diff   ci_lwr   ci_upr        p_val\nmean in group drought -11.57936 9.621373 13.53734 4.732468e-17\n\n\nHowever, this list isn’t super nice to look at. We could bind the rows into a data frame (with list_rbind or dplyr::bind_rows), or we could just made a data frame in the first place with map_dfr, which will always output a data frame (well, a tibble). Note that map_dfr is technically “superseded” because it requires the dplyr package to be installed, but it still works fine if you do.\n\n## quick t test each dependent variable\nttest_df &lt;- map_dfr(.x = c(\"height_cm\", \"dry_biomass_g\", \"seed_mass_mg\"),\n                    .f = quick_t_test,\n                    dat = plant_data, treatment = \"treatment\")\n\n## show results\nttest_df\n\n                           mean_diff   ci_lwr    ci_upr        p_val\nmean in group drought...1  -4.245301 3.059107  5.431496 1.683137e-09\nmean in group drought...2  -9.071756 5.592005 12.551508 2.664831e-06\nmean in group drought...3 -11.579357 9.621373 13.537341 4.732468e-17\n\n\nMuch nicer right? (just ignore those row names, we could remove them if we wanted). There are map functions that specifically output all sorts of data structures, like vectors of specific data types (e.g., map_chr for strings, map_int for integers). There is even a map functional that provides no output but iteratively performs a function: walk(). You could use walk when you want to iteratively draw plots or save files.\nOne thing that is also helpful is that you can write a function withing a map functional, if you just need to do something over and over again but don’t need to use the function elsewhere. So we could have done this:\n\nttest_df2 &lt;- map_dfr(.x = c(\"height_cm\", \"dry_biomass_g\", \"seed_mass_mg\"),\n                     .f = function(x){\n                       ## do t test\n                       test_result &lt;- t.test(plant_data[,x] ~ \n                                             plant_data[,\"treatment\"])\n                       ## pull out summary\n                       clean_result &lt;- data.frame(mean_diff = diff(test_result$estimate),\n                                                  ci_lwr = test_result$conf.int[1],\n                                                  ci_upr = test_result$conf.int[2],\n                                                  p_val = test_result$p.value)\n                       ## return the clean_result as output from the function\n                       return(clean_result)\n                      })\n\n\n\n5.0.2 Iterating over Two Ranges with map2\nYou can also iterate over two ranges of values with map2 functionals, or many with pmap functionals. Let’s try it with our data by calculating the covariance between each pair of our dependent variables (there are likely other functions for this, but again, this is just a demo):\n\n## first let's find the pairs of our variables with combn\nvar_coms &lt;- combn(x = c(\"height_cm\", \"dry_biomass_g\", \"seed_mass_mg\"), m = 2)\nvar_coms\n\n     [,1]            [,2]           [,3]           \n[1,] \"height_cm\"     \"height_cm\"    \"dry_biomass_g\"\n[2,] \"dry_biomass_g\" \"seed_mass_mg\" \"seed_mass_mg\" \n\n## we can use the two rows as our iterating ranges\n\n## use map2_dbl to coerce to numeric vector\nvar_covs &lt;- map2_dbl(.x = var_coms[1,], .y = var_coms[2,],\n                     .f = function(x, y){ ## use a wrapper function to set the data frame\n                      cov(plant_data[,x], plant_data[y])\n                     })\nvar_covs\n\n[1] 11.08664 13.40739 25.47608\n\n\nHere we didn’t just use “cov” because we wanted to pull the data from the plant_data data frame, so we used a “wrapper” function so that we could more precisely set the arguments of cov().\nWe can put all of our info together like so:\n\nplant_covs &lt;- data.frame(var1 = var_coms[1,],\n                         var2 = var_coms[2,],\n                         cov = var_covs)\n\nplant_covs\n\n           var1          var2      cov\n1     height_cm dry_biomass_g 11.08664\n2     height_cm  seed_mass_mg 13.40739\n3 dry_biomass_g  seed_mass_mg 25.47608\n\n\nWe could have also plugged the map functional right into our data.frame construction. If you are familiar with dplyr and use mutate, you can mutate new columns using map as well!\n\n\n5.0.3 Concluding Remarks (that sounds too formal…)\nSince the above demonstrations are relatively simple, you may be skeptical of the advantages of writing custom functions to iterate with functionals like map. And if you prefer to use loops, just use loops! You can do a lot of cool stuff with for loops. However, I think it’s always nice to add more techniques to your “coding toolbox,” as you can solve more problems.\nParticularly, as your code gets more complex and interconnected, and your project gets larger, functions and functionals can really come in handy for keeping things organized. For example, I have a simulation project where I have a function to generate simulated landscapes, functions to look at those landscapes, a function to simulate animal movement over those landscapes, and a function that applies parasitic interactions with those animals (the animal movement function is called within this function). This way I can pinpoint where bugs might be easily and transfer my landscape generation or movement functions to other projects. Perhaps most importantly, I can use map to try generating landscapes and simulating movement under a range of different parameters. This general organizational concept could be applied to more analytical projects where you are aalyzing and plotting different datasets in different ways.\nIn the end, you have the most important opinion on how you code, so try using functionals and see how they can be best integrated into your coding!\nIf you’d like to learn more than this shallow introduction, check this link out:\nhttps://purrr.tidyverse.org/"
  },
  {
    "objectID": "parallel_computing.html",
    "href": "parallel_computing.html",
    "title": "6  Parallel Computing with map",
    "section": "",
    "text": "If you want to go really fast, you can improve the performance of map functionals by using the parallel computing versions of them. Basically you can split the iterations you are doing among different R sessions or processing cores to shorten the total time to finish them all.\nTo demonstrate, I want to first make a function that is slow to run. It takes a while to calculate the distance matrix of a set of coordinates, especially if there’s a lot of them. So I will make a function that does just that (don’t worry about what actually is being done here, just that it is slow):\n\n## load purrr library for later\nlibrary(purrr)\n\n## set the only argument to be the size of the coordinate system, with a default of 1000\n## store output temporarily and then delete it to clear up memory\nlong_function &lt;- function(size = 1000){\n  temp &lt;- dist(c(1:size, 1:size))\n  rm(temp)\n}\n\n## runs without errors (defaults to size = 1000)\nlong_function()\n\nNow let’s try running this function multiple times with walk (which is a purrr functional that gives no output), and measure how much time it takes. There a fancy ways to do this with performance check packages, but a simple way is to check the time before running, and then after running, and checking the difference (you need to run the code all at once for this to work though).\n\n### run this block all at once\n## save start time\nstart &lt;- Sys.time()\n## iterate long function for 1000 iterations of the same size value\nwalk(.x = rep(1000, 1000), .f = long_function)\n## save end time\nend &lt;- Sys.time()\n## calculate runtime\nend - start\n\nTime difference of 4.880572 secs\n\n###\n\nThe time difference varies on my machine, but for me it’s usually around or above 5 seconds. Obviously that’s not terribly long, but good for demonstration purposes. If we instead chunk those 500 iterations to be performed in prralel by separate R sessions, we should be able to divide that runtime by as many sessions as you have.\nFor this we need the “furrr” package (hey it rhymes with purrr!), as well as it’s dependency “future”.\n\ninstall.packages(\"furrr\")\n\n## if it doesn't install future automatically....\ninstall.packages(\"future\")\n\nThen we need to set the “plan” to use multiple R sessions. This is basically telling the alternative map functional that we will use in the next step how to evaluate its process, sequentially or in parallel with multiple sessions (or cores, or even machines).\n\n## load furrr\nlibrary(furrr)\n\nLoading required package: future\n\n## set plan to use 5 R sessions\nplan(multisession, workers = 5)\n\nNow we can use “future_walk” to run the function for 1000 iterations in ~1/5th the time!\n\n### run this block all at once\n## save start time\nstart &lt;- Sys.time()\n## iterate long function for 1000 iterations of the same size value\nfuture_walk(.x = rep(1000, 1000), .f = long_function)\n## save end time\nend &lt;- Sys.time()\n## calculate runtime\nend - start\n\nTime difference of 1.990603 secs\n\n###\n\nThis usually runs in less than 2 seconds! Wheee! Obviously in this case, a &gt;50% reduction in time doesn’t add up to much in seconds, but when your function takes hours, you can work much faster with furrr.\nThis is a very surface level demo, but should be good enough to speed up some of your code. There is a lot of depth to this topic that I’m not equipped to speak on, so do look here for more info:\nhttps://furrr.futureverse.org/index.html\nAnd the plan function in particular is good to understand:\nhttps://www.rdocumentation.org/packages/future/versions/1.33.0/topics/plan"
  },
  {
    "objectID": "vectorization.html",
    "href": "vectorization.html",
    "title": "7  Vectorization",
    "section": "",
    "text": "So the last thing I want to mention is the fastest way to iterate, and one that you have already done - vectorization. Many of R’s base functions are written in C, which is much faster than R, so simple iterations can be done much faster. These functions are referred to as “vectorized”, or you are basically performing vector math with them. Here is a simple example: let’s find the 1 through 6th powers of 2:\n\n## we could write a loop\nfor (i in 1:6){\n  print(i^2)\n}\n\n[1] 1\n[1] 4\n[1] 9\n[1] 16\n[1] 25\n[1] 36\n\n## or we could use a functional\nlibrary(purrr)\nmap_int(.x = 1:6, .f = function(x){2^x})\n\n[1]  2  4  8 16 32 64\n\n## or we could simply use vector math; the \"^\" function is written in C, so...\n2^(1:6)\n\n[1]  2  4  8 16 32 64\n\n\nThe third solution (which is the fastest) may have been obvious to you, but sometimes it’s not so obvious.\nConsider simulating an animal that moves randomly around an infinite grid (or perhaps simulating Brownian motion of particles). If you wanted to track that animal/particles position at each of 100 timesteps, it seems like a for loop would be your best bet. The position of the animal at one time step depends in part on its position in the last time step, right? So let’s show that:\n\n## create a matrix to keep track of positions\nanimal_coords &lt;- matrix(NA, nrow = 101, ncol = 2)\n## start our animal at the origin of the infinite grid\nanimal_coords[1,] &lt;- c(0,0)\n\n## move it 100 times\nfor (i in 1:100){\n  animal_coords[i+1,1] &lt;- animal_coords[i,1] + sample(x = c(1,0,-1), size = 1)\n  animal_coords[i+1,2] &lt;- animal_coords[i,2] + sample(x = c(1,0,-1), size = 1)\n}\n\nSo that works, and it’s plenty fast for a single run of 100 timesteps, but increase the timesteps and simulate over some parameter space and it gets lengthy. Luckily, base R has a helpful vectorized function for this: cumsum. It calculates the cumulative sum of a vector at each index. So we can also write our random walk like this:\n\n## cumulatively sum random movements for the x and y coordinate\nx_coords &lt;- cumsum(c(0, sample(c(1,0,-1), size = 100, replace = TRUE)))\ny_coords &lt;- cumsum(c(0, sample(c(1,0,-1), size = 100, replace = TRUE)))\n\n## bind those coords\nnew_animal_coords &lt;- cbind(x_coords, y_coords)\n\n(Note: for random walks across higher dimension arrays, writing a function and iterating over each axis would be advisable).\nThat method would save you a lot of time if you were running tons of simulations! Basically, we are outsourcing our for loop to C with the cumsum function. When you can, outsource iterations to C! (Although it may take some time digging around base R functions to find what you need)."
  }
]